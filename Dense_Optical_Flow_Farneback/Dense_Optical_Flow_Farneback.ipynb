{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Optical Flow with Gunnar Farneb채ck's Algorithm\n",
    "\n",
    "Dense optical flow aims to identify the movement of each pixel across a series of\n",
    "images. In this notebook, I'll build Farneb채ck's algorithm from the ground up. Dense\n",
    "optical flow is important in fields such as structure from motion, video compression,\n",
    "and video stabilization, among others.\n",
    "\n",
    "**RULES:** As usual, **`OpenCV`** is banned in this repository.\n",
    "\n",
    "**References:**\n",
    "\n",
    "-   [1]\n",
    "    [Optical Flow - Michael Black - MLSS 2013 T체bingen](https://www.youtube.com/watch?v=tIwpDuqJqcE)\n",
    "\n",
    "-   [2]\n",
    "    [Polynomial Expansion for Orientation and Motion Estimation](https://www.ida.liu.se/ext/WITAS-ev/Computer_Vision_Technologies/PaperInfo/farneback02.html)\n",
    "    \n",
    "-   [3]\n",
    "    [ericPrince's Pure python implementation of Gunnar Farneback's optical flow algorithm](https://github.com/ericPrince/optical-flow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import correlate1d\n",
    "from functools import partial\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import my_utils\n",
    "\n",
    "# np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "In the world of computer vision, understanding how pixels move between images in a sequence is crucial. This process involves tracking the displacement of pixels across consecutive frames, which is based on two key assumptions:\n",
    "\n",
    "**Assumptions:**\n",
    "\n",
    "1. **Brightness Constancy:** This principle states that the brightness of a pixel remains constant between consecutive images, despite its movement to a new position. This idea is captured by the equation:\n",
    "\n",
    "   $$\n",
    "   I(x + u, y + v, t + 1) = I(x, y, t)\n",
    "   $$\n",
    "\n",
    "   Here, $u$ and $v$ represent the horizontal and vertical shifts in the pixel's position, illustrating that the pixel's intensity doesn't change as it moves.\n",
    "\n",
    "2. **Spatial Smoothness:** This assumption is based on the idea that neighboring pixels usually move in a similar fashion because they are likely part of the same surface. Surfaces tend to be smooth, implying that adjacent pixels will have comparable motion. This concept is summarized as follows:\n",
    "\n",
    "   $$\n",
    "   u_p = u_n \\quad \\text{and} \\quad v_p = v_n, \\quad \\forall n \\in G(p)\n",
    "   $$\n",
    "\n",
    "   It means that the movement of a pixel $p$ in both horizontal ($u$) and vertical ($v$) directions is similar to that of its neighboring pixel $n$, suggesting that optical flow changes smoothly across the image.\n",
    "\n",
    "**Objective Function:**\n",
    "\n",
    "Derived from these assumptions, the objective functions are:\n",
    "\n",
    "-   **Brightness Constancy:**\n",
    "\n",
    "    $$\n",
    "    E_D(u, v) = \\sum (I(x + u, y + v, t + 1) - I(x, y, t))^2\n",
    "    $$\n",
    "\n",
    "    This equation emphasizes that deviations from brightness constancy are minimized, assuming the presence of Gaussian noise.\n",
    "\n",
    "-   **Spatial Smoothness:**\n",
    "\n",
    "    $$\n",
    "    E_s(u, v) = \\sum(u_p - u_n)^2 + \\sum(v_p - v_n)^2, \\quad \\forall n \\in G(p)\n",
    "    $$\n",
    "\n",
    "    This formula encourages smoothness by penalizing variations in the motion between a pixel and its neighbors.\n",
    "\n",
    "**Solving the Equations**\n",
    "\n",
    "The principle of brightness constancy implies that a pixel's intensity does not change over time as it moves. This is mathematically represented as:\n",
    "\n",
    "$$\n",
    "I(x, y, t) = I(x + \\Delta x, y + \\Delta y, t + \\Delta t)\n",
    "$$\n",
    "\n",
    "For slight movements ($\\Delta x$, $\\Delta y$, $\\Delta t$), we can use the first-order Taylor series expansion for image intensity $I$:\n",
    "\n",
    "$$\n",
    "I(x + \\Delta x, y + \\Delta y, t + \\Delta t) \\approx I(x, y, t) + \\frac{\\partial I}{\\partial x} \\Delta x + \\frac{\\partial I}{\\partial y} \\Delta y + \\frac{\\partial I}{\\partial t} \\Delta t\n",
    "$$\n",
    "\n",
    "By applying the brightness constancy condition and simplifying, we eliminate the term $I(x, y, t)$ on both sides:\n",
    "\n",
    "$$\n",
    "I_x \\Delta x + I_y \\Delta y + I_t \\Delta t = 0\n",
    "$$\n",
    "\n",
    "Dividing through by $\\Delta t$ (assuming it is not zero) and using $\\Delta x / \\Delta t = u$ and $\\Delta y / \\Delta t = v$ for velocity components, we arrive at the optical flow constraint equation:\n",
    "\n",
    "$$\n",
    "I_x u + I_y v + I_t = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## polynomial expansion for orientation and motion estimation\n",
    "\n",
    "In Gunnar Farneb채ck's thesis and related work on optical flow and image analysis, the\n",
    "polynomial expansion of local neighborhoods around each pixel is used to approximate the\n",
    "local image structure and motion. This approach, often associated with the estimation of\n",
    "optical flow, involves fitting a polynomial to the intensity values of a local\n",
    "neighborhood around each pixel in an image. The quadratic, linear, and constant terms in\n",
    "this polynomial expansion have specific interpretations relating to the image's local\n",
    "structure and motion. Let's break down what A, B, and C represent in the context of a 2D\n",
    "grayscale image and their physical interpretations:\n",
    "\n",
    "**Quadratic Term (A):** The quadratic term, represented by matrix A, captures the\n",
    "curvature of the image intensity surface in the local neighborhood of a pixel. This term\n",
    "can be thought of as containing coefficients of a quadratic polynomial that models how\n",
    "the intensity varies in two dimensions. It reflects the local geometric structure of the\n",
    "image around each pixel, such as edges, corners, or flat areas. High values in this term\n",
    "indicate regions with high curvature or rapid changes in intensity, which often\n",
    "correspond to edges or texture in the image.\n",
    "\n",
    "**Linear Term (B):** The linear term, represented by vector B, captures the first-order\n",
    "change in intensity in the local neighborhood, essentially representing the gradient of\n",
    "the image at each pixel. This term indicates the direction and magnitude of the most\n",
    "significant intensity change. In the context of motion, it can be related to the primary\n",
    "direction of motion or flow in the local area. This term is crucial for understanding\n",
    "the orientation and intensity gradient of features within the image.\n",
    "\n",
    "**Constant Term (C):** The constant term, represented by C, corresponds to the average\n",
    "or base intensity level within the local neighborhood around a pixel. It represents the\n",
    "overall intensity offset of the local region. This term is less about the local\n",
    "structure or motion and more about the general brightness or darkness of the area.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal, Certainty, and Applicability\n",
    "\n",
    "Let $f$ represent the complete signal, while $\\hat{f}$ signifies the local neighborhood\n",
    "around a specific point. It is important to note that the neighborhood is of finite\n",
    "size, making $\\hat{f}$ a member of a finite-dimensional vector space, denoted as $C^n$.\n",
    "Regardless of the space's dimensionality it resides in, $\\hat{f}$ is depicted as an\n",
    "$n \\times 1$ column vector. Certainty quantifies our confidence in the signal's values\n",
    "at each location, represented by non-negative real numbers. The symbol $c$ encapsulates\n",
    "the entire field of certainty, while the $n \\times 1$ column vector $\\hat{c}$\n",
    "specifically denotes the certainty levels within $\\hat{f}$. Applicability refers to a\n",
    "unique form of \"certainty\" applicable to the basis functions. Rather than acting as a\n",
    "direct measure of certainty or confidence, it highlights the relevance or significance\n",
    "of each point within the neighborhood. Like certainty, applicability, denoted by $a$, is\n",
    "expressed as an $n \\times 1$ vector consisting of non-negative values. Points of zero\n",
    "applicability could technically be omitted from the neighborhood; however, practical\n",
    "considerations might justify their inclusion. Although intuitively it might seem\n",
    "appropriate to confine applicability values within the $[0, 1]$ range, such restrictions\n",
    "are unnecessary as the scale of these values is ultimately irrelevant.\n",
    "\n",
    "For further details on generating applicability, refer to page 43 and Section 3.10 of\n",
    "[1]. The functions `generate_applicability` and `generate_certainty` are implemented as\n",
    "follows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_applicability(sigma):\n",
    "    \"\"\"Calculate 1D Gaussian applicability kernel.\"\"\"\n",
    "    n = int(4 * sigma + 1)  # Capture significant parts of the Gaussian distribution\n",
    "    x = np.arange(-n, n + 1)\n",
    "    applicability = np.exp(-(x**2) / (2 * sigma**2))\n",
    "    return x, applicability\n",
    "\n",
    "\n",
    "def generate_certainty(height, width, denominator=5):\n",
    "    \"\"\"should it be gaussion or linear\"\"\"\n",
    "    kernel = np.minimum(\n",
    "        1,\n",
    "        1 / denominator * np.minimum(np.arange(height)[:, None], np.arange(width)),\n",
    "    )\n",
    "    kernel = np.minimum(\n",
    "        kernel,\n",
    "        1\n",
    "        / denominator\n",
    "        * np.minimum(\n",
    "            height - 1 - np.arange(height)[:, None],\n",
    "            width - 1 - np.arange(width),\n",
    "        ),\n",
    "    )\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separable Correlation\n",
    "\n",
    "Separable correlation is a versatile computational strategy employed across various\n",
    "domains, including signal processing and image analysis. This technique simplifies\n",
    "correlation operations, significantly enhancing efficiency, particularly when dealing\n",
    "with large filters or kernels. The essence of separability lies in the ability to\n",
    "decompose a two-dimensional kernel into two orthogonal one-dimensional kernels. Such\n",
    "decomposition enables the execution of two-dimensional correlation operations as a\n",
    "series of two sequential one-dimensional processes, initially across rows and\n",
    "subsequently down columns, or vice versa.\n",
    "\n",
    "To understand this concept mathematically, consider a two-dimensional kernel $H$ that\n",
    "can be represented as the outer product of two one-dimensional vectors, $u$ and $v$:\n",
    "\n",
    "$$\n",
    "H = u \\otimes v\n",
    "$$\n",
    "\n",
    "In this expression, $\\otimes$ symbolizes the outer product. A kernel is deemed separable\n",
    "if it is possible to identify vectors $u$ and $v$ for which the above relationship is\n",
    "true.\n",
    "\n",
    "When applying this to an input signal or image, denoted as $I$, the operation of\n",
    "two-dimensional correlation with a separable kernel $H$ unfolds in two distinct phases:\n",
    "\n",
    "1. **Horizontal Pass:** The initial one-dimensional kernel $u$ is applied across each\n",
    "   row of $I$.\n",
    "2. **Vertical Pass:** Subsequently, the second one-dimensional kernel $v$ is applied\n",
    "   down each column of the result from the horizontal pass.\n",
    "\n",
    "Adopting this strategy substantially lowers computational complexity. In a scenario\n",
    "involving a signal with dimensions $M \\times N$ and a kernel sized $K \\times K$,\n",
    "executing a conventional two-dimensional correlation requires $O(MNK^2)$\n",
    "multiplications. Conversely, with separable correlation, the requisite number of\n",
    "multiplications drops to $O(MNK + MNK) = O(2MNK)$, marking a significant reduction.\n",
    "\n",
    "While the term \"separable correlation\" might broadly encompass any correlation operation\n",
    "(including autocorrelation) that benefits from separability, it underscores the\n",
    "computational efficiency gained by decomposing complex operations into more manageable,\n",
    "sequential steps. Regardless of its specific application, the principle of separability\n",
    "facilitates more resource-efficient computations, proving invaluable in enhancing\n",
    "performance and expediting processing times in numerous applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_exp(f, certainty, sigma):\n",
    "    x, applicability = generate_applicability(sigma)\n",
    "\n",
    "    # b: calculate b from the paper. Calculate separately for X and Y dimensions\n",
    "    # [n, 6]\n",
    "    bx = np.stack(\n",
    "        [\n",
    "            np.ones(applicability.shape),\n",
    "            x,\n",
    "            np.ones(applicability.shape),\n",
    "            x**2,\n",
    "            np.ones(applicability.shape),\n",
    "            x,\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )\n",
    "    by = np.stack(\n",
    "        [\n",
    "            np.ones(applicability.shape),\n",
    "            np.ones(applicability.shape),\n",
    "            x,\n",
    "            np.ones(applicability.shape),\n",
    "            x**2,\n",
    "            x,\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )\n",
    "\n",
    "    # Pre-calculate product of certainty and signal\n",
    "    cf = certainty * f\n",
    "\n",
    "    # G and v are used to calculate \"r\" from the paper: v = G*r. eg. 4.9\n",
    "    # r is the parametrization of the 2nd order polynomial for f\n",
    "    G = np.empty(list(f.shape) + [bx.shape[-1]] * 2)\n",
    "    v = np.empty(\n",
    "        list(f.shape) + [bx.shape[-1]]\n",
    "    )  #  the product of the signal and the applicability\n",
    "\n",
    "    # Apply separable cross-correlations\n",
    "\n",
    "    # Pre-calculate quantities recommended in paper\n",
    "    ab = np.einsum(\"i,ij->ij\", applicability, bx)\n",
    "    abb = np.einsum(\"ij,ik->ijk\", ab, bx)\n",
    "\n",
    "    # Calculate G and v for each pixel with cross-correlation\n",
    "    for i in range(bx.shape[-1]):\n",
    "        for j in range(bx.shape[-1]):\n",
    "            G[..., i, j] = correlate1d(\n",
    "                certainty, abb[..., i, j], axis=0, mode=\"constant\", cval=0\n",
    "            )  # use certainty\n",
    "\n",
    "        v[..., i] = correlate1d(cf, ab[..., i], axis=0, mode=\"constant\", cval=0)\n",
    "\n",
    "    # Pre-calculate quantities recommended in paper\n",
    "    ab = np.einsum(\"i,ij->ij\", applicability, by)\n",
    "    abb = np.einsum(\"ij,ik->ijk\", ab, by)\n",
    "\n",
    "    # Calculate G and v for each pixel with cross-correlation\n",
    "    for i in range(bx.shape[-1]):\n",
    "        for j in range(bx.shape[-1]):\n",
    "            G[..., i, j] = correlate1d(\n",
    "                G[..., i, j], abb[..., i, j], axis=1, mode=\"constant\", cval=0\n",
    "            )  # use G\n",
    "\n",
    "        v[..., i] = correlate1d(v[..., i], ab[..., i], axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "    # Solve r for each pixel\n",
    "    r = np.linalg.solve(G, v)\n",
    "\n",
    "    # Quadratic term\n",
    "    A = np.empty(list(f.shape) + [2, 2])\n",
    "    A[..., 0, 0] = r[..., 3]\n",
    "    A[..., 0, 1] = r[..., 5] / 2\n",
    "    A[..., 1, 0] = A[..., 0, 1]\n",
    "    A[..., 1, 1] = r[..., 4]\n",
    "\n",
    "    # Linear term\n",
    "    B = np.empty(list(f.shape) + [2])\n",
    "    B[..., 0] = r[..., 1]\n",
    "    B[..., 1] = r[..., 2]\n",
    "\n",
    "    # constant term\n",
    "    C = r[..., 0]\n",
    "\n",
    "    # b: [n, n, 6]\n",
    "    # r: [f, f, 6]\n",
    "    # f: [f, f]\n",
    "    # e = b*r - f, eg. 3.19\n",
    "\n",
    "    return A, B, C\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the polynomial expansion function `poly_exp`, we can proceed to visualize\n",
    "the variables `A`, `B`, and `C`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"input/yosemite/yos02.tif\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "print(\"img:\", img.shape, img.dtype, img.min(), img.max())\n",
    "# TODO: Use float64 should also work. Input image should be floating point.\n",
    "# gray = gray.astype(np.float64)\n",
    "# gray /= 255\n",
    "print(f\"gray: {gray.shape}, {gray.dtype}, {gray.min()}, {gray.max()}\")\n",
    "\n",
    "height, width, *_ = img.shape\n",
    "certainty = generate_certainty(height, width, denominator=5)\n",
    "print(f\"certainty: {certainty.shape}, {certainty.dtype}, {certainty.min()}, {certainty.max()}\")\n",
    "\n",
    "A, B, C = poly_exp(f=gray, certainty=certainty, sigma=4)\n",
    "print(\"A:\", A.shape)\n",
    "print(\"B:\", B.shape)\n",
    "print(\"C:\", C.shape)\n",
    "\n",
    "my_utils.visualize_polynomial_expansion(\n",
    "    img, A, B, C, out_path=\"./output/polynomial_expansion.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displacement Estimation\n",
    "\n",
    "Since the result of polynomial expansion is that each neighborhood is approximated by a\n",
    "polynomial, it becomes interesting to analyze what happens if a polynomial undergoes an\n",
    "ideal translation. Consider the exact quadratic polynomial:\n",
    "\n",
    "$$\n",
    "f_1(x) = x^T A_1 x + b_1^T x + c_1\n",
    "$$\n",
    "\n",
    "and construct a new signal $f_2$ by a global displacement by $d$ as in eg. 7.2 in [2]\n",
    "\n",
    "$$\n",
    "f_2(x) = f_1(x - d) = x^T A_2 x + b_2^T x + c_2.\n",
    "$$\n",
    "\n",
    "Equating the coefficients in the quadratic polynomials yields\n",
    "\n",
    "$$\n",
    "A_2 = A_1,\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_2 = b_1 - 2A_1 d,\n",
    "$$\n",
    "\n",
    "$$\n",
    "c_2 = d^T A_1 d - b_1^T d + c_1.\n",
    "$$\n",
    "\n",
    "The key observation is that by equation $b_2 = b_1 - 2A_1 d$, we can solve for the\n",
    "translation $d$, at least if $A_1$ is non-singular,\n",
    "\n",
    "$$\n",
    "d = -\\frac{1}{2} A_1^{-1} (b_2 - b_1).\n",
    "$$\n",
    "\n",
    "We note that this observation holds for any signal dimensionality.\n",
    "\n",
    "The intuitive explanation is that the stationary points of\n",
    "\n",
    "$$\n",
    "f(x) = x^T Ax + b^T x + c\n",
    "$$\n",
    "\n",
    "can be found by differentiating \\(f\\) and setting the result to 0,\n",
    "\n",
    "$$\n",
    "\\nabla f(x) = 2Ax + b = 0,\n",
    "$$\n",
    "\n",
    "$$\n",
    "x = -\\frac{1}{2} A^{-1} b.\n",
    "$$\n",
    "\n",
    "If we assume that \\(A\\) is non-singular and rewrite the equation for \\(d\\) as\n",
    "\n",
    "$$\n",
    "d = \\left(-\\frac{1}{2} A_2^{-1} b_2\\right) - \\left(-\\frac{1}{2} A_1^{-1} b_1\\right),\n",
    "$$\n",
    "\n",
    "we obtain the displacement as the observed movement of the stationary point.\n",
    "\n",
    "Obviously, the assumptions that an entire signal can be represented as a single\n",
    "polynomial and that two signals are related by a global translation are quite\n",
    "unrealistic. Nonetheless, the basic relation can still be applied to real signals, even\n",
    "though errors are introduced when these assumptions are relaxed. The question then\n",
    "becomes whether these errors can be kept small enough to yield useful algorithms.\n",
    "\n",
    "To address this, in practical consideratino, we start by replacing the global polynomial\n",
    "described in the equation with local polynomial approximations. This means conducting a\n",
    "polynomial expansion of both images, resulting in expansion coefficients $A_1(x)$,\n",
    "$b_1(x)$, and $c_1(x)$ for the first image and $A_2(x)$, $b_2(x)$, and\n",
    "$c_2(x)$ for the second image. Ideally, this should result in $A_1 = A_2$ according\n",
    "to the earlier equation, but in practice, we have to settle for the approximation\n",
    "\n",
    "$$\n",
    "A(x) = \\frac{A_1(x) + A_2(x)}{2}.\n",
    "$$\n",
    "\n",
    "We also introduce\n",
    "\n",
    "$$\n",
    "\\Delta b(x) = -\\frac{1}{2}(b_2(x) - b_1(x))\n",
    "$$\n",
    "\n",
    "to obtain the primary constraint\n",
    "\n",
    "$$\n",
    "A(x)d(x) = \\Delta b(x),\n",
    "$$\n",
    "\n",
    "where \\(d(x)\\) indicates that we have also replaced the global displacement with a\n",
    "spatially varying displacement field.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculating displacement over a neightborhood\n",
    "\n",
    "In this section, we return to the challenge of estimating a general displacement field, not limited to the x-axis. As observed in the previous section, a pointwise solution of \n",
    "\n",
    "$$\n",
    "A(x)d(x) = \\Delta b(x),\n",
    "$$ \n",
    "\n",
    "does not yield satisfactory outcomes. To enhance this, we adopt the assumption, as before, that the displacement field varies only gradually. This time, our aim is to find $d(x)$ that satisfies \n",
    "\n",
    "$$\n",
    "A(x)d(x) = \\Delta b(x),\n",
    "$$ \n",
    "\n",
    "as closely as possible over a neighborhood $I$ of $x$, or more formally, by minimizing\n",
    "\n",
    "$$\n",
    "\\sum_{\\Delta x \\in I} w(\\Delta x)\\|A(x + \\Delta x)d(x) - \\Delta b(x + \\Delta x)\\|^2,\n",
    "$$\n",
    "\n",
    "where $w(\\Delta x)$ acts as a weight function (applicability). The minimum is obtained for\n",
    "\n",
    "$$\n",
    "d(x) = \\left(\\sum wA^T A\\right)^{-1} \\sum wA^T \\Delta b,\n",
    "$$\n",
    "\n",
    "having simplified some indices for readability. The minimum value is given by\n",
    "\n",
    "$$\n",
    "e(x) = \\sum w\\Delta b^T \\Delta b - d(x)^T \\left(\\sum wA^T \\Delta b\\right).\n",
    "$$\n",
    "\n",
    "In practical terms, this means we compute $A^T A$, $A^T \\Delta b$, and $\\Delta b^T \\Delta b$ pointwise and average these with $w$ before solving for the displacement. The minimum value $e(x)$ serves as a reversed confidence indicator, where smaller numbers signify higher confidence. The solution presented exists and is unique unless the entire neighborhood faces the aperture problem.\n",
    "\n",
    "At times, it may be beneficial to include a certainty weight $c(x + \\Delta x)$ in the equation. This adjustment is most straightforwardly addressed by scaling $A$ and $\\Delta b$ accordingly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimating a parameterized displacement field\n",
    "\n",
    "Like in section 6.3, we can improve robustness if the displacement field can be\n",
    "parameterized according to some motion model. The approach is very similar, and we\n",
    "derive it for the eight-parameter model in 2D, given by equation (6.6),\n",
    "\n",
    "$$\n",
    "d_x(x, y) = a_1 + a_2 x + a_3 y + a_7 x^2 + a_8 xy,\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_y(x, y) = a_4 + a_5 x + a_6 y + a_7 xy + a_8 y^2.\n",
    "$$\n",
    "\n",
    "We can rewrite this in matrix form similar to (6.28) and (6.29), except that we do not\n",
    "have an extra temporal dimension,\n",
    "\n",
    "$$\n",
    "d = Sp,\n",
    "$$\n",
    "\n",
    "$$\n",
    "S = \\left[ \\begin{array}{cc}\n",
    "1 & x & y & 0 & 0 & 0 & x^2 & xy \\\\\n",
    "0 & 0 & 0 & 1 & x & y & xy & y^2 \\\\\n",
    "\\end{array} \\right],\n",
    "$$\n",
    "\n",
    "$$\n",
    "p = \\left[ \\begin{array}{c}\n",
    "a_1 \\\\\n",
    "a_2 \\\\\n",
    "a_3 \\\\\n",
    "a_4 \\\\\n",
    "a_5 \\\\\n",
    "a_6 \\\\\n",
    "a_7 \\\\\n",
    "a_8 \\\\\n",
    "\\end{array} \\right].\n",
    "$$\n",
    "\n",
    "Inserting into equation for the weighted least squares problem,\n",
    "\n",
    "$$\n",
    "\\sum w_i \\|A_i S_i p - \\Delta b_i\\|^2,\n",
    "$$\n",
    "\n",
    "where we use $i$ to index the coordinates in a neighborhood. The solution is\n",
    "\n",
    "$$\n",
    "p = \\left( \\sum w_i S_i^T A_i^T A_i S_i \\right)^{-1} \\sum w_i S_i^T A_i^T \\Delta b_i.\n",
    "$$\n",
    "\n",
    "We can notice that, just as in section 6.3, any motion model which is linear in its\n",
    "parameters can be used. We also notice that, like in the previous section, we can\n",
    "compute $S^T A^T AS$ and $S^T A^T \\Delta b$ pointwise and then average these with $w$.\n",
    "In fact, the solution reduces to the previous equation for the constant motion model.\n",
    "\n",
    "A minor variation of the idea is to approximate the entire signal with one parametric\n",
    "displacement field, allowing us to compute the parameters by\n",
    "\n",
    "$$\n",
    "p = \\left( \\sum S_i^T A_i^T A_i S_i \\right)^{-1} \\sum S_i^T A_i^T \\Delta b_i,\n",
    "$$\n",
    "\n",
    "where the summation is over the whole signal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motion_model(x, model):\n",
    "    # Evaluate warp parametrization model at pixel coordinates\n",
    "    if model == \"constant\":\n",
    "        S = np.eye(2)\n",
    "\n",
    "    elif model in (\"affine\", \"eight_param\"):\n",
    "        # (height, width, 6 or 8)\n",
    "        S = np.empty(list(x.shape) + [6 if model == \"affine\" else 8])\n",
    "\n",
    "        S[..., 0, 0] = 1\n",
    "        S[..., 0, 1] = x[..., 0]\n",
    "        S[..., 0, 2] = x[..., 1]\n",
    "        S[..., 0, 3] = 0\n",
    "        S[..., 0, 4] = 0\n",
    "        S[..., 0, 5] = 0\n",
    "\n",
    "        S[..., 1, 0] = 0\n",
    "        S[..., 1, 1] = 0\n",
    "        S[..., 1, 2] = 0\n",
    "        S[..., 1, 3] = 1\n",
    "        S[..., 1, 4] = x[..., 0]\n",
    "        S[..., 1, 5] = x[..., 1]\n",
    "\n",
    "        if model == \"eight_param\":\n",
    "            S[..., 0, 6] = x[..., 0] ** 2\n",
    "            S[..., 0, 7] = x[..., 0] * x[..., 1]\n",
    "\n",
    "            S[..., 1, 6] = x[..., 0] * x[..., 1]\n",
    "            S[..., 1, 7] = x[..., 1] ** 2\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid parametrization model\")\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporating Prior Knowledge\n",
    "\n",
    "A principal challenge with the method so far is the assumption that local polynomials at\n",
    "the same coordinates in two signals are identical, except for a displacement. Since the\n",
    "polynomial expansions are local models, they will vary spatially, introducing errors in\n",
    "the constraints\n",
    "\n",
    "$$\n",
    "A(x)d(x) = \\Delta b(x).\n",
    "$$\n",
    "\n",
    "For small displacements, this issue is not too severe, but it becomes more problematic\n",
    "with larger displacements. Fortunately, we are not limited to comparing two polynomials\n",
    "at the exact same coordinate. If we possess prior knowledge about the displacement\n",
    "field, we can compare the polynomial at $x$ in the first signal to the polynomial at\n",
    "$x + \\tilde{d}(x)$ in the second signal, where $\\tilde{d}(x)$ is the initial\n",
    "displacement field rounded to integer values. This approach essentially allows us to\n",
    "estimate the relative displacement between the real value and the rounded a priori\n",
    "estimate, which is hopefully smaller.\n",
    "\n",
    "This observation is incorporated into the algorithm by replacing the equations\n",
    "\n",
    "$$\n",
    "A(x) = \\frac{A_1(x) + A_2(\\tilde{x})}{2},\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Delta b(x) = -\\frac{1}{2}(b_2(\\tilde{x}) - b_1(x)) + A(x) \\tilde{d}(x),\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\tilde{x} = x + \\tilde{d}(x).\n",
    "$$\n",
    "\n",
    "The first two terms in $\\Delta b$ are involved in computing the remaining displacement,\n",
    "while the last term adds back the rounded a priori displacement. We can observe that for\n",
    "$\\tilde{d}$ identically zero, these equations revert to the original form, as would be\n",
    "expected.\n",
    "\n",
    "The displacement estimation algorithm derived in the last three sections is illustrated\n",
    "with a block diagram in figure 7.8. Inputs are the quadratic polynomial expansion\n",
    "coefficients for the two signals, $A_1$, $b_1$, $A_2$, $b_2$, and an a priori\n",
    "displacement field $d_{in}$. The output is the estimated displacement field $d_{out}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Displacement Estimation\n",
    "\n",
    "The simplest solution, as depicted in figure 7.9, involves iterating the displacement\n",
    "estimation process three times. The output displacement from one iteration serves as the\n",
    "a priori displacement for the subsequent iteration. Initially, the a priori displacement\n",
    "field $d_{in}$ is typically set to zero, unless there is actual knowledge available\n",
    "about the displacement field. The same polynomial expansion coefficients are utilized\n",
    "across all iterations and are required to be computed only once. While it is feasible to\n",
    "set a fixed number of iterations, iterating until the displacement estimates have\n",
    "converged is also a viable approach.\n",
    "\n",
    "The vulnerability of this method lies primarily in the first iteration. If the\n",
    "displacements (relative to the a priori displacements) are excessively large, it is\n",
    "unreasonable to anticipate improvements in the output displacements, rendering further\n",
    "iterations ineffective.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-scale Displacement Estimation\n",
    "\n",
    "The issue of overly large displacements can be mitigated by performing the analysis at a\n",
    "coarser scale. This entails utilizing a larger applicability kernel for the polynomial\n",
    "expansion and/or applying a lowpass filter to the signal first, as discussed in section\n",
    "4.5. The result is an algorithm capable of handling larger displacements, albeit with a\n",
    "decrease in accuracy.\n",
    "\n",
    "This leads to the adoption of a multi-scale approach. Begin with a coarse scale to\n",
    "achieve a rough yet reasonable displacement estimate, and then refine this estimate\n",
    "across finer scales to achieve progressively more accurate estimates. Figure 7.10\n",
    "illustrates a diagram for a three-scale displacement estimation algorithm. To minimize\n",
    "computations, both signals $f_1$ and $f_2$ are lowpass filtered and subsampled between\n",
    "scales, but the algorithm is compatible with any multi-scale polynomial expansion\n",
    "scheme. If the signal undergoes subsampling, it's necessary to upsample the estimated\n",
    "displacement fields between scales, adjusting the values to match the new scale\n",
    "accordingly. As in previous methods, the a priori displacement $d_{in}$ at the coarsest\n",
    "scale is initially set to zero, unless there is direct knowledge of the displacement\n",
    "field.\n",
    "\n",
    "Unlike the iterative displacement estimation algorithm, this method necessitates the\n",
    "calculation of new polynomial expansion coefficients for each scale. However, as we will\n",
    "see in the following section, this only marginally impacts the computational complexity,\n",
    "especially if subsampling is employed. It's also possible to integrate both strategies,\n",
    "iterating multiple times at each scale, although this might not be an efficient\n",
    "practice, except perhaps at the coarsest scale.\n",
    "\n",
    "notice that `gen_gaussian_pyramids` will convert the output to floating point ranging\n",
    "from 0 to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_gaussian_pyramids(img_list, n_pyr):\n",
    "    \"\"\"\n",
    "    Applies Gaussian pyramid transformations to a list of images, zips the transformed images together,\n",
    "    and then reverses the order of the resulting list.\n",
    "\n",
    "    Parameters:\n",
    "    - img_list: List of images to transform. Each image should be compatible with skimage.transform.pyramid_gaussian.\n",
    "    - n_pyr: The number of pyramid layers to use in the transformation.\n",
    "\n",
    "    Returns:\n",
    "    - A reversed list of the zipped, pyramid-transformed images.\n",
    "    \"\"\"\n",
    "    # Apply the Gaussian pyramid transformation to each image in the list with the specified number of layers\n",
    "    transformed_images = list(\n",
    "        map(partial(skimage.transform.pyramid_gaussian, max_layer=n_pyr), img_list)\n",
    "    )\n",
    "\n",
    "    # Zip the transformed images together and reverse the order\n",
    "    zipped_and_reversed = reversed(list(zip(*transformed_images)))\n",
    "\n",
    "    return zipped_and_reversed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Noise\n",
    "\n",
    "Upon closely examining the residual displacement field, it becomes evident that the\n",
    "majority of noise originates from areas that either lack significant structures or have\n",
    "very low contrast. Notably, this issue is pronounced in regions experiencing the\n",
    "aperture problem, leading to noise within the parallel displacement components. To\n",
    "address this, a technique involves \"enforcing\" the background field onto estimates that\n",
    "are uncertain. This is achieved by incorporating a regularization term into equation\n",
    "(7.22), aiming to minimize the expression:\n",
    "\n",
    "$$\n",
    "\\sum_{\\Delta x \\in I} w(\\Delta x)\\|A(x + \\Delta x)d(x) - \\Delta b(x + \\Delta x)\\|^2 + \\mu\\|d(x) - d' (x)\\|^2,\n",
    "$$\n",
    "\n",
    "where $d'$ denotes the previously estimated background displacement field, and $\\mu$\n",
    "represents a constant. The underlying concept is that the regularization term exerts\n",
    "minimal impact when the displacement is strongly constrained by the summation in the\n",
    "formula but becomes significant in its absence. This method is particularly effective\n",
    "for the aperture problem, where the normal component is well-constrained, unlike the\n",
    "parallel component. The solution to equation (7.35) is articulated as:\n",
    "\n",
    "$$\n",
    "d(x) = \\left(\\mu I + \\sum wA^T A\\right)^{-1} \\left(\\mu d'(x) + \\sum wA^T \\Delta b\\right),\n",
    "$$\n",
    "\n",
    "simplifying the notation to enhance readability. Figure 7.19 outlines a block diagram\n",
    "for the modified basic displacement estimation algorithm. This can be integrated with\n",
    "the processes depicted in either figure 7.9 or figure 7.10 for iterative or multi-scale\n",
    "algorithm variations.\n",
    "\n",
    "Selecting an appropriate value for $\\mu$ remains an open challenge. The method we\n",
    "explored involves setting $\\mu$ to the mean of half the trace of $G_{avg}$ (referencing\n",
    "the notation from figure 7.19), calculated across the entire image. Although this\n",
    "approach markedly diminishes noise, it also tends to decrease the magnitude of actual\n",
    "residuals. In the context of motion detection, this compromise is deemed reasonable.\n",
    "Figure 7.20 displays both the total and residual displacement fields from figures 7.2(a)\n",
    "and 7.18(b), re-evaluated using this refined algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_displacement_with_regularization(A, S_T, S, delB, w, mu):\n",
    "    # Pre-calculate quantities recommended by paper\n",
    "    A_T = A.swapaxes(-1, -2)\n",
    "    ATA = S_T @ A_T @ A @ S\n",
    "    ATb = (S_T @ A_T @ delB[..., None])[..., 0]\n",
    "    # btb = delB.swapaxes(-1, -2) @ delB\n",
    "    G_avg = np.mean(ATA, axis=(0, 1))\n",
    "    h_avg = np.mean(ATb, axis=(0, 1))\n",
    "    p_avg = np.linalg.solve(G_avg, h_avg)  # fig. 7.8\n",
    "    d_avg = (S @ p_avg[..., None])[..., 0]\n",
    "\n",
    "    # Default value for mu is to set mu to 1/2 the trace of G_avg\n",
    "    if mu is None:\n",
    "        mu = 1 / 2 * np.trace(G_avg)\n",
    "\n",
    "    # Apply separable cross-correlation to calculate linear equation\n",
    "    # G = correlate1d(A_T @ A, w, axis=0, mode=\"constant\", cval=0)\n",
    "    G = correlate1d(ATA, w, axis=0, mode=\"constant\", cval=0)\n",
    "    G = correlate1d(G, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "    # h = correlate1d(\n",
    "    #     (A_T @ delB[..., None])[..., 0], w, axis=0, mode=\"constant\", cval=0\n",
    "    # )\n",
    "    h = correlate1d(ATb, w, axis=0, mode=\"constant\", cval=0)\n",
    "    h = correlate1d(h, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "    # Refine estimate of displacement field\n",
    "    d = np.linalg.solve(G + mu * np.eye(2), h + mu * d_avg)\n",
    "    return d\n",
    "\n",
    "\n",
    "def estimate_displacement_without_regularization(A, S_T, S, delB, w):\n",
    "    # Pre-calculate quantities recommended by paper\n",
    "    A_T = A.swapaxes(-1, -2)\n",
    "    ATA = S_T @ A_T @ A @ S\n",
    "    ATb = (S_T @ A_T @ delB[..., None])[..., 0]\n",
    "    # btb = delB.swapaxes(-1, -2) @ delB\n",
    "\n",
    "    # If mu is 0, it means the global/average parametrized warp should not be\n",
    "    # calculated, and the parametrization should apply to the local calculations\n",
    "    # if mu == 0: # page 132\n",
    "    # Apply separable cross-correlation to calculate linear equation\n",
    "    # for each pixel: G*d = h\n",
    "    G = correlate1d(ATA, w, axis=0, mode=\"constant\", cval=0)\n",
    "    G = correlate1d(G, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "    h = correlate1d(ATb, w, axis=0, mode=\"constant\", cval=0)\n",
    "    h = correlate1d(h, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "    d = (S @ np.linalg.solve(G, h)[..., None])[..., 0]\n",
    "    return d\n",
    "\n",
    "\n",
    "def flow_iterative(\n",
    "    f1, f2, sigma, sigma_flow, num_iter=1, d=None, model=\"constant\", mu=None\n",
    "):\n",
    "\n",
    "    # TODO: add initial warp parameters as optional input?\n",
    "\n",
    "    height, width, *_ = f1.shape\n",
    "    c1 = generate_certainty(height, width, 5)  # (height, width) float64 0.0 1.0\n",
    "    c2 = generate_certainty(height, width, 5)  # (height, width) float64 0.0 1.0\n",
    "\n",
    "    # Calculate the polynomial expansion at each point in the images\n",
    "    A1, B1, C1 = poly_exp(f1, c1, sigma)\n",
    "    A2, B2, C2 = poly_exp(f2, c2, sigma)\n",
    "\n",
    "    # Pixel coordinates of each point in the images, (height, width, 2)\n",
    "    x = np.stack(\n",
    "        np.broadcast_arrays(np.arange(f1.shape[0])[:, None], np.arange(f1.shape[1])),\n",
    "        axis=-1,\n",
    "    ).astype(int)\n",
    "\n",
    "    # Initialize displacement field\n",
    "    if d is None:\n",
    "        d = np.zeros(list(f1.shape) + [2])  # (height, width, 2)\n",
    "\n",
    "    # Set up applicability convolution window\n",
    "    n_flow = int(4 * sigma_flow + 1)\n",
    "    xw = np.arange(-n_flow, n_flow + 1)\n",
    "    w = np.exp(-(xw**2) / (2 * sigma_flow**2))\n",
    "\n",
    "    S = motion_model(x, model)\n",
    "\n",
    "    S_T = S.swapaxes(-1, -2)\n",
    "\n",
    "    # Iterate convolutions to estimate the optical flow\n",
    "    for _ in range(num_iter):\n",
    "        # Set d~ as displacement field fit to nearest pixel (and constrain to not\n",
    "        # being off image). Note we are setting certainty to 0 for points that\n",
    "        # would have been off-image had we not constrained them\n",
    "        d_ = d.astype(int)  # priori displacement\n",
    "        x_ = x + d_\n",
    "\n",
    "        # x_ = np.maximum(np.minimum(x_, np.array(f1.shape) - 1), 0)\n",
    "\n",
    "        # Constrain d~ to be on-image, and find points that would have\n",
    "        # been off-image\n",
    "        x_2 = np.maximum(np.minimum(x_, np.array(f1.shape) - 1), 0)\n",
    "        off_f = np.any(x_ != x_2, axis=-1)\n",
    "        x_ = x_2\n",
    "\n",
    "        # Set certainty to 0 for off-image points\n",
    "        c_ = c1[x_[..., 0], x_[..., 1]]\n",
    "        c_[off_f] = 0\n",
    "\n",
    "        # Calculate A and delB for each point, according to paper\n",
    "        A = (A1 + A2[x_[..., 0], x_[..., 1]]) / 2\n",
    "        A *= c_[\n",
    "            ..., None, None\n",
    "        ]  # recommendation in paper: add in certainty by applying to A and delB\n",
    "\n",
    "        delB = -1 / 2 * (B2[x_[..., 0], x_[..., 1]] - B1) + (A @ d_[..., None])[..., 0]\n",
    "        delB *= c_[\n",
    "            ..., None\n",
    "        ]  # recommendation in paper: add in certainty by applying to A and delB\n",
    "\n",
    "        if mu == 0:\n",
    "            d = estimate_displacement_without_regularization(A, S_T, S, delB, w)\n",
    "        else:\n",
    "            d = estimate_displacement_with_regularization(A, S_T, S, delB, w, mu)\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_optical_flow_farneback(img1, img2):\n",
    "    assert img1.shape == img2.shape\n",
    "\n",
    "    n_pyr = 3\n",
    "    opts = dict(\n",
    "        sigma=4.0,\n",
    "        sigma_flow=4.0,\n",
    "        num_iter=3,\n",
    "        model=\"constant\",\n",
    "        mu=None,  # if mu is zero, there will be singularity error in linalg error. Use None and let it be computed automatically\n",
    "    )\n",
    "\n",
    "    d = None  # optical flow field\n",
    "\n",
    "    gaussion_pyramids = gen_gaussian_pyramids([img1, img2], n_pyr=n_pyr)\n",
    "    for pyr1, pyr2 in gaussion_pyramids:\n",
    "        if d is not None:\n",
    "            # TODO: account for shapes not quite matching\n",
    "            d = skimage.transform.pyramid_expand(d, channel_axis=-1)\n",
    "            d = d[: pyr1.shape[0], : pyr2.shape[1]] * 2\n",
    "\n",
    "        d = flow_iterative(pyr1, pyr2, d=d, **opts)\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(cv2.samples.findFile(\"input/snatch.mp4\"))  # 25 fps\n",
    "ret, frame1 = cap.read()\n",
    "prev = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "# prev: (1080, 1920) uint8 0 255\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[..., 1] = 255\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # Codec\n",
    "print(\"cap.get(cv2.CAP_PROP_FPS)\", cap.get(cv2.CAP_PROP_FPS))\n",
    "out = cv2.VideoWriter(\n",
    "    \"./output/snatch_optical_flow.mp4\",\n",
    "    fourcc,\n",
    "    fps=cap.get(cv2.CAP_PROP_FPS),\n",
    "    frameSize=(frame1.shape[1], frame1.shape[0]),\n",
    ")\n",
    "\n",
    "stop = 1\n",
    "while 1:\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret or stop == 0:\n",
    "        print(\"No frames grabbed!\")\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # next: (1080, 1920) uint8 0 255\n",
    "\n",
    "    flow = calc_optical_flow_farneback(prev, next)\n",
    "    # flow: (1080, 1920, 2) float64\n",
    "\n",
    "    bgr = my_utils.flow_to_color(flow, hsv)\n",
    "\n",
    "    # out.write(bgr)\n",
    "    cv2.imwrite(\"./output_farneback.png\", bgr)\n",
    "\n",
    "    # cv2.imshow(\"frame2\", bgr)\n",
    "    # k = cv2.waitKey(30) & 0xFF\n",
    "    # if k == 27:\n",
    "    #     break\n",
    "    # elif k == ord(\"s\"):\n",
    "    #     cv2.imwrite(\"opticalfb.png\", frame2)\n",
    "    #     cv2.imwrite(\"opticalhsv.png\", bgr)\n",
    "\n",
    "    prev = next\n",
    "    stop -= 1\n",
    "    print(\"stop: \", stop)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_computer_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
