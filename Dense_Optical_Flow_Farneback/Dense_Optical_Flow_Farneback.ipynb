{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense Optical Flow with Gunnar Farneb채ck's Algorithm\n",
    "\n",
    "Dense optical flow identifies the movement of each pixel across a series of images. In\n",
    "this notebook, I'll build Farneb채ck's algorithm from the ground up.\n",
    "\n",
    "**RULES:** As usual, **`OpenCV`** is banned in this repository.\n",
    "\n",
    "**References:**\n",
    "\n",
    "-   [1]\n",
    "    [Polynomial Expansion for Orientation and Motion Estimation](https://www.ida.liu.se/ext/WITAS-ev/Computer_Vision_Technologies/PaperInfo/farneback02.html)\n",
    "\n",
    "-   [2]\n",
    "    [Optical Flow - Michael Black - MLSS 2013 T체bingen](https://www.youtube.com/watch?v=tIwpDuqJqcE)\n",
    "\n",
    "-   [3]\n",
    "    [ericPrince's Pure python implementation of Gunnar Farneback's optical flow algorithm](https://github.com/ericPrince/optical-flow)\n",
    "\n",
    "**Important Note:** To fully grasp Farneb채ck's Algorithm, I highly recommend reading\n",
    "[1]. This notebook provides a foundational overview, sufficient for basic learning but\n",
    "not an exhaustive understanding of the algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import correlate1d\n",
    "from functools import partial\n",
    "import skimage\n",
    "import my_utils\n",
    "\n",
    "# np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "In the world of computer vision, tracking the displacement of pixels across consecutive\n",
    "frames is usually based on two assumptions:\n",
    "\n",
    "1. **Brightness Constancy:** It states that the brightness of a pixel remains constant\n",
    "   between consecutive images, despite its movement to a new position. This idea is\n",
    "   captured by the equation:\n",
    "\n",
    "    $$\n",
    "    I(x + u, y + v, t + 1) = I(x, y, t)\n",
    "    $$\n",
    "\n",
    "    Here, $u$ and $v$ represent the horizontal and vertical shifts in the pixel's\n",
    "    position, illustrating that the pixel's intensity doesn't change as it moves.\n",
    "\n",
    "2. **Spatial Smoothness:** It is based on the idea that neighboring pixels usually move\n",
    "   in a similar fashion because they are likely part of the same surface. Surfaces tend\n",
    "   to be smooth, implying that adjacent pixels will have comparable motion. This concept\n",
    "   is summarized as follows:\n",
    "\n",
    "    $$\n",
    "    u_p = u_n \\quad \\text{and} \\quad v_p = v_n, \\quad \\forall n \\in G(p)\n",
    "    $$\n",
    "\n",
    "    It means that the movement of a pixel $p$ in both horizontal ($u$) and vertical\n",
    "    ($v$) directions is similar to that of its neighboring pixel $n$, suggesting that\n",
    "    optical flow changes smoothly across the image.\n",
    "\n",
    "**Objective Function:**\n",
    "\n",
    "Derived from these assumptions, we can define the objective functions as follow:\n",
    "\n",
    "-   **Brightness Constancy:**\n",
    "\n",
    "    $$\n",
    "    E_D(u, v) = \\sum (I(x + u, y + v, t + 1) - I(x, y, t))^2\n",
    "    $$\n",
    "\n",
    "    This equation emphasizes that deviations from brightness constancy are minimized,\n",
    "    assuming the presence of Gaussian noise.\n",
    "\n",
    "-   **Spatial Smoothness:**\n",
    "\n",
    "    $$\n",
    "    E_s(u, v) = \\sum(u_p - u_n)^2 + \\sum(v_p - v_n)^2, \\quad \\forall n \\in G(p)\n",
    "    $$\n",
    "\n",
    "    This formula encourages smoothness by penalizing variations in the motion between a\n",
    "    pixel and its neighbors.\n",
    "\n",
    "**Solving the Equations**\n",
    "\n",
    "The principle of brightness constancy implies that a pixel's intensity does not change\n",
    "over time as it moves. This is mathematically represented as:\n",
    "\n",
    "$$\n",
    "I(x, y, t) = I(x + \\Delta x, y + \\Delta y, t + \\Delta t)\n",
    "$$\n",
    "\n",
    "For slight movements ($\\Delta x$, $\\Delta y$, $\\Delta t$), we can use the first-order\n",
    "Taylor series expansion for image intensity $I$:\n",
    "\n",
    "$$\n",
    "I(x + \\Delta x, y + \\Delta y, t + \\Delta t) \\approx I(x, y, t) + \\frac{\\partial I}{\\partial x} \\Delta x + \\frac{\\partial I}{\\partial y} \\Delta y + \\frac{\\partial I}{\\partial t} \\Delta t\n",
    "$$\n",
    "\n",
    "By applying the brightness constancy condition and simplifying, we eliminate the term\n",
    "$I(x, y, t)$ on both sides:\n",
    "\n",
    "$$\n",
    "I_x \\Delta x + I_y \\Delta y + I_t \\Delta t = 0\n",
    "$$\n",
    "\n",
    "Dividing through by $\\Delta t$ (assuming it is not zero) and using\n",
    "$\\Delta x / \\Delta t = u$ and $\\Delta y / \\Delta t = v$ for velocity components, we\n",
    "arrive at the optical flow constraint equation:\n",
    "\n",
    "$$\n",
    "I_x u + I_y v + I_t = 0\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Expansion for Orientation and Motion Estimation\n",
    "\n",
    "Polynomial expansion fits polynomials to local pixel neighborhoods to approximate image\n",
    "motion and structure as detailed in [1]. It uses quadratic, linear, and constant terms\n",
    "(A, B, C) to describe local image structure and motion:\n",
    "\n",
    "-   **Quadratic Term (A):** Represents the curvature of the image intensity surface,\n",
    "    indicating the geometric structure like edges or flat areas. High values signal\n",
    "    significant curvature or rapid intensity changes.\n",
    "\n",
    "-   **Linear Term (B):** Represents the gradient at each pixel, showing the direction\n",
    "    and magnitude of the most substantial intensity change, crucial for identifying\n",
    "    motion direction and feature orientation.\n",
    "\n",
    "-   **Constant Term (C):** Represents the average intensity in a pixel's neighborhood,\n",
    "    indicating the area's overall brightness or darkness without detailing structure or\n",
    "    motion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal, Certainty, and Applicability\n",
    "\n",
    "The signal $f$ and its local approximation $\\hat{f}$, a finite-dimensional vector in\n",
    "$C^n$, reflect the signal within a specific neighborhood, represented as an $n \\times 1$\n",
    "column vector.\n",
    "\n",
    "**Certainty** is the confidence in signal values, indicated by non-negative real\n",
    "numbers. The field of certainty is $c$, with $\\hat{c}$ as the $n \\times 1$ vector for\n",
    "local certainty levels.\n",
    "\n",
    "**Applicability** defines the relevance of basis functions within the neighborhood,\n",
    "expressed as non-negative values in an $n \\times 1$ vector, $a$. Unlike certainty,\n",
    "applicability focuses on the significance of each point, with non-zero values indicating\n",
    "relevance. While intuitively applicability might range between $[0, 1]$, no such\n",
    "restriction is necessary, as the scale of these values doesn't impact their relevance.\n",
    "\n",
    "For generating applicability and certainty specifics, see page 43 and Section 3.10 of\n",
    "[1]. The functions `generate_applicability` and `generate_certainty` detail their\n",
    "implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_applicability(sigma):\n",
    "    \"\"\"Calculate 1D Gaussian applicability kernel.\"\"\"\n",
    "    n = int(4 * sigma + 1)  # Capture significant parts of the Gaussian distribution\n",
    "    x = np.arange(-n, n + 1)\n",
    "    applicability = np.exp(-(x**2) / (2 * sigma**2))\n",
    "    return x, applicability\n",
    "\n",
    "\n",
    "def generate_certainty(height, width, denominator=5):\n",
    "    \"\"\"should it be gaussion or linear\"\"\"\n",
    "    kernel = np.minimum(\n",
    "        1,\n",
    "        1 / denominator * np.minimum(np.arange(height)[:, None], np.arange(width)),\n",
    "    )\n",
    "    kernel = np.minimum(\n",
    "        kernel,\n",
    "        1\n",
    "        / denominator\n",
    "        * np.minimum(\n",
    "            height - 1 - np.arange(height)[:, None],\n",
    "            width - 1 - np.arange(width),\n",
    "        ),\n",
    "    )\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separable Correlation\n",
    "\n",
    "Separable correlation is a technique that enhances computational efficiency in signal\n",
    "processing and image analysis by simplifying correlation operations, especially with\n",
    "large filters. It involves decomposing a two-dimensional kernel into two orthogonal\n",
    "one-dimensional kernels, allowing two-dimensional correlation to be performed as two\n",
    "separate one-dimensional processes: first across rows, then down columns, or vice versa.\n",
    "\n",
    "Mathematically, if a two-dimensional kernel $H$ can be expressed as the outer product of\n",
    "two one-dimensional vectors $u$ and $v$:\n",
    "\n",
    "$$\n",
    "H = u \\otimes v\n",
    "$$\n",
    "\n",
    "then the kernel is separable. For an input signal or image $I$, the two-dimensional\n",
    "correlation with a separable kernel $H$ occurs in two phases:\n",
    "\n",
    "1. **Horizontal Pass:** Apply one-dimensional kernel $u$ across each row of $I$.\n",
    "2. **Vertical Pass:** Apply one-dimensional kernel $v$ down each column of the\n",
    "   horizontal pass result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining `poly_exp`\n",
    "\n",
    "To construct the polynomial expansion function `poly_exp`, we follow the guidelines of\n",
    "Chapter 4 in [1]. The process is divided into four main parts:\n",
    "\n",
    "-   **Initialization and Applicability Generation:** Detailed on page 43, this step\n",
    "    involves setting up the initial conditions and generating the applicability matrix\n",
    "    based on $\\sigma$.\n",
    "\n",
    "-   **Calculation of Polynomial Coefficients `b`:** As described in Section 4.3, this\n",
    "    involves calculating the polynomial expansion coefficients for horizontal\n",
    "    (x-direction) and vertical (y-direction) correlations separately. This step also\n",
    "    includes multiplying the certainty map with the image signal to prioritize signal\n",
    "    values based on their certainty.\n",
    "\n",
    "-   **Cross-Correlation and Polynomial Parameters Calculation:** Utilizes matrices `G`\n",
    "    and `v` to solve for `r` using Eq. 4.9, where $r = G^{-1}v$. Here, `r` represents\n",
    "    the parameters of the second-order polynomial modeling the signal `f`.\n",
    "\n",
    "-   **Final Polynomial Terms Extraction:** Based on equations 4.3 and 4.4, the quadratic\n",
    "    (`A`), linear (`B`), and constant (`C`) terms of the polynomial are derived,\n",
    "    respectively.\n",
    "\n",
    "Finally, the dimensions of the coefficients and residual error calculation are\n",
    "summarized as follows:\n",
    "\n",
    "-   Coefficient `b`: (n, n, 6)\n",
    "-   Parameters `r`: (f, f, 6)\n",
    "-   Signal `f`: (f, f)\n",
    "-   Residual error $e$ is calculated as $\\|b \\cdot r - f\\|_W$, as shown in equation 3.19.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_exp(f, certainty, sigma):\n",
    "    # Initialization and Applicability Generation\n",
    "    height, width = f.shape\n",
    "    x, applicability = generate_applicability(sigma)\n",
    "\n",
    "    # Calculation of Polynomial Coefficients `b`\n",
    "    bx = np.stack(\n",
    "        [\n",
    "            np.ones(applicability.shape),\n",
    "            x,\n",
    "            np.ones(applicability.shape),\n",
    "            x**2,\n",
    "            np.ones(applicability.shape),\n",
    "            x,\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )  # (n, 6)\n",
    "    by = np.stack(\n",
    "        [\n",
    "            np.ones(applicability.shape),\n",
    "            np.ones(applicability.shape),\n",
    "            x,\n",
    "            np.ones(applicability.shape),\n",
    "            x**2,\n",
    "            x,\n",
    "        ],\n",
    "        axis=-1,\n",
    "    )  # (n, 6)\n",
    "\n",
    "    # Pre-calculate product of certainty and signal\n",
    "    cf = certainty * f\n",
    "\n",
    "    # Cross-Correlation and Polynomial Parameters Calculation\n",
    "    G = np.empty(list(f.shape) + [bx.shape[-1]] * 2)  # (height, width, 6, 6)\n",
    "    v = np.empty(list(f.shape) + [bx.shape[-1]])  # (height, width, 6)\n",
    "\n",
    "    # Apply separable cross-correlations\n",
    "    # Pre-calculate quantities.\n",
    "    ab = np.einsum(\"i,ij->ij\", applicability, bx)\n",
    "    abb = np.einsum(\"ij,ik->ijk\", ab, bx)\n",
    "    # Calculate G and v for each pixel with cross-correlation\n",
    "    for i in range(bx.shape[-1]):\n",
    "        for j in range(bx.shape[-1]):\n",
    "            G[..., i, j] = correlate1d(\n",
    "                certainty, abb[..., i, j], axis=0, mode=\"constant\", cval=0\n",
    "            )\n",
    "\n",
    "        v[..., i] = correlate1d(cf, ab[..., i], axis=0, mode=\"constant\", cval=0)\n",
    "\n",
    "    # Pre-calculate quantities.\n",
    "    ab = np.einsum(\"i,ij->ij\", applicability, by)\n",
    "    abb = np.einsum(\"ij,ik->ijk\", ab, by)\n",
    "    # Calculate G and v for each pixel with cross-correlation\n",
    "    for i in range(bx.shape[-1]):\n",
    "        for j in range(bx.shape[-1]):\n",
    "            G[..., i, j] = correlate1d(\n",
    "                G[..., i, j], abb[..., i, j], axis=1, mode=\"constant\", cval=0\n",
    "            )\n",
    "\n",
    "        v[..., i] = correlate1d(v[..., i], ab[..., i], axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "    # Solve r for each pixel\n",
    "    r = np.linalg.solve(G, v)\n",
    "\n",
    "    # Final Polynomial Terms Extraction\n",
    "    # Quadratic term\n",
    "    A = np.empty(list(f.shape) + [2, 2])\n",
    "    A[..., 0, 0] = r[..., 3]\n",
    "    A[..., 0, 1] = r[..., 5] / 2\n",
    "    A[..., 1, 0] = A[..., 0, 1]\n",
    "    A[..., 1, 1] = r[..., 4]\n",
    "\n",
    "    # Linear term\n",
    "    B = np.empty(list(f.shape) + [2])\n",
    "    B[..., 0] = r[..., 1]\n",
    "    B[..., 1] = r[..., 2]\n",
    "\n",
    "    # constant term\n",
    "    C = r[..., 0]\n",
    "\n",
    "    return A, B, C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the polynomial expansion function `poly_exp`, we can visualize the terms\n",
    "`A`, `B`, and `C` as follows. The quadratic term `A` captures the even part of the\n",
    "signal, while the linear term `B` encapsulates the odd part. Meanwhile, `C` reflects\n",
    "variations in the local differential convolution level.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"input/yosemite/yos02.tif\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "print(\"img:\", img.shape, img.dtype, img.min(), img.max())\n",
    "# TODO: Use float64 should also work. Input image should be floating point.\n",
    "# gray = gray.astype(np.float64)\n",
    "# gray /= 255\n",
    "print(f\"gray: {gray.shape}, {gray.dtype}, {gray.min()}, {gray.max()}\")\n",
    "\n",
    "height, width, *_ = img.shape\n",
    "certainty = generate_certainty(height, width, denominator=5)\n",
    "print(f\"certainty: {certainty.shape}, {certainty.dtype}, {certainty.min()}, {certainty.max()}\")\n",
    "\n",
    "A, B, C = poly_exp(f=gray, certainty=certainty, sigma=4)\n",
    "print(\"A:\", A.shape)\n",
    "print(\"B:\", B.shape)\n",
    "print(\"C:\", C.shape)\n",
    "\n",
    "my_utils.visualize_polynomial_expansion(\n",
    "    img, A, B, C, out_path=\"./output/polynomial_expansion.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displacement Estimation\n",
    "\n",
    "Polynomial expansion allows for approximating the neighborhood of a pixel. When considering an ideal translation, we analyze the behavior of a quadratic polynomial signal:\n",
    "\n",
    "$$\n",
    "f_1(x) = x^T A_1 x + b_1^T x + c_1\n",
    "$$\n",
    "\n",
    "and construct a new signal $f_2$ displaced globally by $d$, as shown in equation 7.2 in [1]:\n",
    "\n",
    "$$\n",
    "f_2(x) = f_1(x - d) = (x^T A_2 x) + (b_2^T x) + c_2.\n",
    "$$\n",
    "\n",
    "By equating coefficients in the quadratic polynomials, we find:\n",
    "\n",
    "- $A_2 = A_1$,\n",
    "- $b_2 = b_1 - 2A_1d$,\n",
    "- $c_2 = d^T A_1 d - b_1^T d + c_1$.\n",
    "\n",
    "For non-singular $A_1$, the translation $d$ can be calculated as:\n",
    "\n",
    "$$\n",
    "d = -\\frac{1}{2} A_1^{-1} (b_2 - b_1).\n",
    "$$\n",
    "\n",
    "This principle, as [1] states, is applicable regardless of signal dimensionality.\n",
    "\n",
    "Furthermore, [1] suggests utilizing local polynomial approximations for each pixel across images, implying the use of $A_1(x)$, $b_1(x)$, and $c_1(x)$ for the first image, and $A_2(x)$, $b_2(x)$, and $c_2(x)$ for the second. Ideally, this would result in $A_1 = A_2$, but practically, an approximation is used:\n",
    "\n",
    "$$\n",
    "A(x) = \\frac{A_1(x) + A_2(x)}{2}.\n",
    "$$\n",
    "\n",
    "Additionally, [1] defines\n",
    "\n",
    "$$\n",
    "\\Delta b(x) = -\\frac{1}{2}(b_2(x) - b_1(x)),\n",
    "$$\n",
    "\n",
    "leading to the primary constraint for displacement estimation:\n",
    "\n",
    "$$\n",
    "A(x)d(x) = \\Delta b(x),\n",
    "$$\n",
    "\n",
    "where $d(x)$ represents a spatially varying displacement field, moving from a global to a local displacement context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Displacement over a Neighborhood\n",
    "\n",
    "Section 7.3 in [1] indicates that solving the equation\n",
    "\n",
    "$$\n",
    "A(x)d(x) = \\Delta b(x),\n",
    "$$\n",
    "\n",
    "pointwise does not yield satisfactory results. To improve accuracy, [1] recommends\n",
    "optimizing the solution across a neighborhood $I$ around $x$. This is achieved by\n",
    "minimizing the weighted sum:\n",
    "\n",
    "$$\n",
    "\\sum_{\\Delta x \\in I} w(\\Delta x)\\|A(x + \\Delta x)d(x) - \\Delta b(x + \\Delta x)\\|^2,\n",
    "$$\n",
    "\n",
    "where $w(\\Delta x)$ serves as a weight function, enhancing the contribution of more\n",
    "relevant points within the neighborhood. The optimal displacement $d(x)$ is found with:\n",
    "\n",
    "$$\n",
    "d(x) = \\left(\\sum wA^T A\\right)^{-1} \\sum wA^T \\Delta b,\n",
    "$$\n",
    "\n",
    "after simplifying the notation for clarity. The corresponding minimum error $e(x)$,\n",
    "indicating the solution's accuracy, is expressed as:\n",
    "\n",
    "$$\n",
    "e(x) = \\sum w\\Delta b^T \\Delta b - d(x)^T \\left(\\sum wA^T \\Delta b\\right).\n",
    "$$\n",
    "\n",
    "This formulation computes $A^T A$, $A^T \\Delta b$, and $\\Delta b^T \\Delta b$ pointwise,\n",
    "then averages these using the weight $w$ before calculating the displacement. The error\n",
    "$e(x)$ inversely relates to confidence: smaller values indicate greater reliability. The\n",
    "solution is both existent and unique unless the neighborhood is uniformly affected by\n",
    "the aperture problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating a Parameterized Displacement Field\n",
    "\n",
    "Following the approach in section 6.3, we can enhance robustness by parameterizing the\n",
    "displacement field according to a specific motion model. For a 2D context, we utilize\n",
    "the eight-parameter model described by equation (6.6):\n",
    "\n",
    "$$\n",
    "d_x(x, y) = a_1 + a_2 x + a_3 y + a_7 x^2 + a_8 xy,\n",
    "$$\n",
    "\n",
    "$$\n",
    "d_y(x, y) = a_4 + a_5 x + a_6 y + a_7 xy + a_8 y^2.\n",
    "$$\n",
    "\n",
    "Expressing this model in matrix form, akin to equations (6.28) and (6.29) but without an\n",
    "extra temporal dimension, we get:\n",
    "\n",
    "$$\n",
    "d = Sp,\n",
    "$$\n",
    "\n",
    "where $S$ is the matrix containing the spatial variables,\n",
    "\n",
    "$$\n",
    "S = \\left[ \\begin{array}{cc}\n",
    "1 & x & y & 0 & 0 & 0 & x^2 & xy \\\\\n",
    "0 & 0 & 0 & 1 & x & y & xy & y^2 \\\\\n",
    "\\end{array} \\right],\n",
    "$$\n",
    "\n",
    "and $p$ is the parameter vector,\n",
    "\n",
    "$$\n",
    "p = \\left[ \\begin{array}{c}\n",
    "a_1 \\\\\n",
    "a_2 \\\\\n",
    "a_3 \\\\\n",
    "a_4 \\\\\n",
    "a_5 \\\\\n",
    "a_6 \\\\\n",
    "a_7 \\\\\n",
    "a_8 \\\\\n",
    "\\end{array} \\right].\n",
    "$$\n",
    "\n",
    "For the weighted least squares problem, we solve\n",
    "\n",
    "$$\n",
    "\\sum w_i \\|A_i S_i p - \\Delta b_i\\|^2,\n",
    "$$\n",
    "\n",
    "where $i$ indexes coordinates in a neighborhood. The solution,\n",
    "\n",
    "$$\n",
    "p = \\left( \\sum w_i S_i^T A_i^T A_i S_i \\right)^{-1} \\sum w_i S_i^T A_i^T \\Delta b_i,\n",
    "$$\n",
    "\n",
    "illustrates that any linearly parameterizable motion model is applicable. As seen in\n",
    "section 6.3, calculations for $S^T A^T AS$ and $S^T A^T \\Delta b$ can be averaged with\n",
    "weights $w$. This methodology echoes the procedure for constant motion models but\n",
    "applies broadly across different parameterizations.\n",
    "\n",
    "An alternative approach suggests using one parametric displacement field to approximate\n",
    "the entire signal, simplifying the calculation of parameters to\n",
    "\n",
    "$$\n",
    "p = \\left( \\sum S_i^T A_i^T A_i S_i \\right)^{-1} \\sum S_i^T A_i^T \\Delta b_i,\n",
    "$$\n",
    "\n",
    "summing over the entire signal to compute the displacement field parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motion_model(x, model):\n",
    "    # Evaluate warp parametrization model at pixel coordinates\n",
    "    if model == \"constant\":\n",
    "        S = np.eye(2)\n",
    "\n",
    "    elif model in (\"affine\", \"eight_param\"):\n",
    "        # (height, width, 6 or 8)\n",
    "        S = np.empty(list(x.shape) + [6 if model == \"affine\" else 8])\n",
    "\n",
    "        S[..., 0, 0] = 1\n",
    "        S[..., 0, 1] = x[..., 0]\n",
    "        S[..., 0, 2] = x[..., 1]\n",
    "        S[..., 0, 3] = 0\n",
    "        S[..., 0, 4] = 0\n",
    "        S[..., 0, 5] = 0\n",
    "\n",
    "        S[..., 1, 0] = 0\n",
    "        S[..., 1, 1] = 0\n",
    "        S[..., 1, 2] = 0\n",
    "        S[..., 1, 3] = 1\n",
    "        S[..., 1, 4] = x[..., 0]\n",
    "        S[..., 1, 5] = x[..., 1]\n",
    "\n",
    "        if model == \"eight_param\":\n",
    "            S[..., 0, 6] = x[..., 0] ** 2\n",
    "            S[..., 0, 7] = x[..., 0] * x[..., 1]\n",
    "\n",
    "            S[..., 1, 6] = x[..., 0] * x[..., 1]\n",
    "            S[..., 1, 7] = x[..., 1] ** 2\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid parametrization model\")\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporating Prior Knowledge\n",
    "\n",
    "A principal challenge with the method so far is the assumption that local polynomials at\n",
    "the same coordinates in two signals are identical, except for a displacement. Since the\n",
    "polynomial expansions are local models, they will vary spatially, introducing errors in\n",
    "the constraints\n",
    "\n",
    "$$\n",
    "A(x)d(x) = \\Delta b(x).\n",
    "$$\n",
    "\n",
    "For small displacements, this issue is not too severe, but it becomes more problematic\n",
    "with larger displacements. Fortunately, we are not limited to comparing two polynomials\n",
    "at the exact same coordinate. If we possess prior knowledge about the displacement\n",
    "field, we can compare the polynomial at $x$ in the first signal to the polynomial at\n",
    "$x + \\tilde{d}(x)$ in the second signal, where $\\tilde{d}(x)$ is the initial\n",
    "displacement field rounded to integer values. This approach essentially allows us to\n",
    "estimate the relative displacement between the real value and the rounded a priori\n",
    "estimate, which is hopefully smaller.\n",
    "\n",
    "This observation is incorporated into the algorithm by replacing the equations\n",
    "\n",
    "$$\n",
    "A(x) = \\frac{A_1(x) + A_2(\\tilde{x})}{2},\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Delta b(x) = -\\frac{1}{2}(b_2(\\tilde{x}) - b_1(x)) + A(x) \\tilde{d}(x),\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\tilde{x} = x + \\tilde{d}(x).\n",
    "$$\n",
    "\n",
    "The first two terms in $\\Delta b$ are involved in computing the remaining displacement,\n",
    "while the last term adds back the rounded a priori displacement. We can observe that for\n",
    "$\\tilde{d}$ identically zero, these equations revert to the original form, as would be\n",
    "expected.\n",
    "\n",
    "The displacement estimation algorithm derived in the last three sections is illustrated\n",
    "with a block diagram below. Inputs are the quadratic polynomial expansion coefficients\n",
    "for the two signals, $A_1$, $b_1$, $A_2$, $b_2$, and an a priori displacement field\n",
    "$d_{in}$. The output is the estimated displacement field $d_{out}$.\n",
    "\n",
    "<figure>\n",
    "  <div style=\"display: flex; justify-content: space-between; max-width: 300px; /* Adjust this value as needed */\">\n",
    "    <div style=\"text-align: center;\">\n",
    "      <img src=\"./images/fig_7_8.png\" style=\"max-width: 100%; height: auto;\">\n",
    "      <p><strong></strong></p>\n",
    "      <p>The block diagram of the basic displacement estimation algorithm (DE) adapted from [1].</p>\n",
    "    </div>\n",
    "  </div>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Noise\n",
    "\n",
    "Upon closely examining the residual displacement field, it becomes evident that the\n",
    "majority of noise originates from areas that either lack significant structures or have\n",
    "very low contrast. Notably, this issue is pronounced in regions experiencing the\n",
    "aperture problem, leading to noise within the parallel displacement components. To\n",
    "address this, a technique involves \"enforcing\" the background field onto estimates that\n",
    "are uncertain. This is achieved by incorporating a regularization term into equation\n",
    "(7.22), aiming to minimize the expression:\n",
    "\n",
    "$$\n",
    "\\sum_{\\Delta x \\in I} w(\\Delta x)\\|A(x + \\Delta x)d(x) - \\Delta b(x + \\Delta x)\\|^2 + \\mu\\|d(x) - d' (x)\\|^2,\n",
    "$$\n",
    "\n",
    "where $d'$ denotes the previously estimated background displacement field, and $\\mu$\n",
    "represents a constant. The underlying concept is that the regularization term exerts\n",
    "minimal impact when the displacement is strongly constrained by the summation in the\n",
    "formula but becomes significant in its absence. This method is particularly effective\n",
    "for the aperture problem, where the normal component is well-constrained, unlike the\n",
    "parallel component. The solution to equation (7.35) is articulated as:\n",
    "\n",
    "$$\n",
    "d(x) = \\left(\\mu I + \\sum wA^T A\\right)^{-1} \\left(\\mu d'(x) + \\sum wA^T \\Delta b\\right),\n",
    "$$\n",
    "\n",
    "simplifying the notation to enhance readability. Figure 7.19 outlines a block diagram\n",
    "for the modified basic displacement estimation algorithm. This can be integrated with\n",
    "the processes depicted in either figure 7.9 or figure 7.10 for iterative or multi-scale\n",
    "algorithm variations.\n",
    "\n",
    "Selecting an appropriate value for $\\mu$ remains an open challenge. The method we\n",
    "explored involves setting $\\mu$ to the mean of half the trace of $G_{avg}$ (referencing\n",
    "the notation from figure 7.19), calculated across the entire image. Although this\n",
    "approach markedly diminishes noise, it also tends to decrease the magnitude of actual\n",
    "residuals. In the context of motion detection, this compromise is deemed reasonable.\n",
    "Figure 7.20 displays both the total and residual displacement fields from figures 7.2(a)\n",
    "and 7.18(b), re-evaluated using this refined algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_displacement_with_regularization(A, S_T, S, delB, w, mu):\n",
    "    # Pre-calculate quantities recommended by paper\n",
    "    A_T = A.swapaxes(-1, -2)\n",
    "    ATA = S_T @ A_T @ A @ S\n",
    "    ATb = (S_T @ A_T @ delB[..., None])[..., 0]\n",
    "    # btb = delB.swapaxes(-1, -2) @ delB\n",
    "    G_avg = np.mean(ATA, axis=(0, 1))\n",
    "    h_avg = np.mean(ATb, axis=(0, 1))\n",
    "    p_avg = np.linalg.solve(G_avg, h_avg)  # fig. 7.8\n",
    "    d_avg = (S @ p_avg[..., None])[..., 0]\n",
    "\n",
    "    # Default value for mu is to set mu to 1/2 the trace of G_avg\n",
    "    if mu is None:\n",
    "        mu = 1 / 2 * np.trace(G_avg)\n",
    "\n",
    "    # Apply separable cross-correlation to calculate linear equation\n",
    "    # G = correlate1d(A_T @ A, w, axis=0, mode=\"constant\", cval=0)\n",
    "    G = correlate1d(ATA, w, axis=0, mode=\"constant\", cval=0)\n",
    "    G = correlate1d(G, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "    # h = correlate1d(\n",
    "    #     (A_T @ delB[..., None])[..., 0], w, axis=0, mode=\"constant\", cval=0\n",
    "    # )\n",
    "    h = correlate1d(ATb, w, axis=0, mode=\"constant\", cval=0)\n",
    "    h = correlate1d(h, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "    # Refine estimate of displacement field\n",
    "    d = np.linalg.solve(G + mu * np.eye(2), h + mu * d_avg)\n",
    "    return d\n",
    "\n",
    "\n",
    "def estimate_displacement_without_regularization(A, S_T, S, delB, w):\n",
    "    # Pre-calculate quantities recommended by paper\n",
    "    A_T = A.swapaxes(-1, -2)\n",
    "    ATA = S_T @ A_T @ A @ S\n",
    "    ATb = (S_T @ A_T @ delB[..., None])[..., 0]\n",
    "    # btb = delB.swapaxes(-1, -2) @ delB\n",
    "\n",
    "    # If mu is 0, it means the global/average parametrized warp should not be\n",
    "    # calculated, and the parametrization should apply to the local calculations\n",
    "    # if mu == 0: # page 132\n",
    "    # Apply separable cross-correlation to calculate linear equation\n",
    "    # for each pixel: G*d = h\n",
    "    G = correlate1d(ATA, w, axis=0, mode=\"constant\", cval=0)\n",
    "    G = correlate1d(G, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "    h = correlate1d(ATb, w, axis=0, mode=\"constant\", cval=0)\n",
    "    h = correlate1d(h, w, axis=1, mode=\"constant\", cval=0)\n",
    "\n",
    "    d = (S @ np.linalg.solve(G, h)[..., None])[..., 0]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-scale Displacement Estimation\n",
    "\n",
    "The issue of overly large displacements can be mitigated by performing the analysis at a\n",
    "coarser scale. This entails utilizing a larger applicability kernel for the polynomial\n",
    "expansion and/or applying a lowpass filter to the signal first, as discussed in section\n",
    "4.5. The result is an algorithm capable of handling larger displacements, albeit with a\n",
    "decrease in accuracy.\n",
    "\n",
    "This leads to the adoption of a multi-scale approach. Begin with a coarse scale to\n",
    "achieve a rough yet reasonable displacement estimate, and then refine this estimate\n",
    "across finer scales to achieve progressively more accurate estimates. Figure 7.10\n",
    "illustrates a diagram for a three-scale displacement estimation algorithm. To minimize\n",
    "computations, both signals $f_1$ and $f_2$ are lowpass filtered and subsampled between\n",
    "scales, but the algorithm is compatible with any multi-scale polynomial expansion\n",
    "scheme. If the signal undergoes subsampling, it's necessary to upsample the estimated\n",
    "displacement fields between scales, adjusting the values to match the new scale\n",
    "accordingly. As in previous methods, the a priori displacement $d_{in}$ at the coarsest\n",
    "scale is initially set to zero, unless there is direct knowledge of the displacement\n",
    "field.\n",
    "\n",
    "Unlike the iterative displacement estimation algorithm, this method necessitates the\n",
    "calculation of new polynomial expansion coefficients for each scale. However, as we will\n",
    "see in the following section, this only marginally impacts the computational complexity,\n",
    "especially if subsampling is employed. It's also possible to integrate both strategies,\n",
    "iterating multiple times at each scale, although this might not be an efficient\n",
    "practice, except perhaps at the coarsest scale.\n",
    "\n",
    "notice that `gen_gaussian_pyramids` will convert the output to floating point ranging\n",
    "from 0 to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_gaussian_pyramids(img_list, n_pyr):\n",
    "    \"\"\"\n",
    "    Applies Gaussian pyramid transformations to a list of images, zips the transformed images together,\n",
    "    and then reverses the order of the resulting list.\n",
    "\n",
    "    Parameters:\n",
    "    - img_list: List of images to transform. Each image should be compatible with skimage.transform.pyramid_gaussian.\n",
    "    - n_pyr: The number of pyramid layers to use in the transformation.\n",
    "\n",
    "    Returns:\n",
    "    - A reversed list of the zipped, pyramid-transformed images.\n",
    "    \"\"\"\n",
    "    # Apply the Gaussian pyramid transformation to each image in the list with the specified number of layers\n",
    "    transformed_images = list(\n",
    "        map(partial(skimage.transform.pyramid_gaussian, max_layer=n_pyr), img_list)\n",
    "    )\n",
    "\n",
    "    # Zip the transformed images together and reverse the order\n",
    "    zipped_and_reversed = reversed(list(zip(*transformed_images)))\n",
    "\n",
    "    return zipped_and_reversed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Displacement Estimation\n",
    "\n",
    "The simplest solution, as depicted in figure 7.9, involves iterating the displacement\n",
    "estimation process three times. The output displacement from one iteration serves as the\n",
    "a priori displacement for the subsequent iteration. Initially, the a priori displacement\n",
    "field $d_{in}$ is typically set to zero, unless there is actual knowledge available\n",
    "about the displacement field. The same polynomial expansion coefficients are utilized\n",
    "across all iterations and are required to be computed only once. While it is feasible to\n",
    "set a fixed number of iterations, iterating until the displacement estimates have\n",
    "converged is also a viable approach.\n",
    "\n",
    "The vulnerability of this method lies primarily in the first iteration. If the\n",
    "displacements (relative to the a priori displacements) are excessively large, it is\n",
    "unreasonable to anticipate improvements in the output displacements, rendering further\n",
    "iterations ineffective.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_iterative(\n",
    "    f1, f2, sigma, sigma_flow, num_iter=1, d=None, model=\"constant\", mu=None\n",
    "):\n",
    "\n",
    "    # TODO: add initial warp parameters as optional input?\n",
    "\n",
    "    height, width, *_ = f1.shape\n",
    "    c1 = generate_certainty(height, width, 5)  # (height, width) float64 0.0 1.0\n",
    "    c2 = generate_certainty(height, width, 5)  # (height, width) float64 0.0 1.0\n",
    "\n",
    "    # Calculate the polynomial expansion at each point in the images\n",
    "    A1, B1, C1 = poly_exp(f1, c1, sigma)\n",
    "    A2, B2, C2 = poly_exp(f2, c2, sigma)\n",
    "\n",
    "    # Pixel coordinates of each point in the images, (height, width, 2)\n",
    "    x = np.stack(\n",
    "        np.broadcast_arrays(np.arange(f1.shape[0])[:, None], np.arange(f1.shape[1])),\n",
    "        axis=-1,\n",
    "    ).astype(int)\n",
    "\n",
    "    # Initialize displacement field\n",
    "    if d is None:\n",
    "        d = np.zeros(list(f1.shape) + [2])  # (height, width, 2)\n",
    "\n",
    "    # Set up applicability convolution window\n",
    "    n_flow = int(4 * sigma_flow + 1)\n",
    "    xw = np.arange(-n_flow, n_flow + 1)\n",
    "    w = np.exp(-(xw**2) / (2 * sigma_flow**2))\n",
    "\n",
    "    S = motion_model(x, model)\n",
    "\n",
    "    S_T = S.swapaxes(-1, -2)\n",
    "\n",
    "    # Iterate convolutions to estimate the optical flow\n",
    "    for _ in range(num_iter):\n",
    "        # Set d~ as displacement field fit to nearest pixel (and constrain to not\n",
    "        # being off image). Note we are setting certainty to 0 for points that\n",
    "        # would have been off-image had we not constrained them\n",
    "        d_ = d.astype(int)  # priori displacement\n",
    "        x_ = x + d_\n",
    "\n",
    "        # x_ = np.maximum(np.minimum(x_, np.array(f1.shape) - 1), 0)\n",
    "\n",
    "        # Constrain d~ to be on-image, and find points that would have\n",
    "        # been off-image\n",
    "        x_2 = np.maximum(np.minimum(x_, np.array(f1.shape) - 1), 0)\n",
    "        off_f = np.any(x_ != x_2, axis=-1)\n",
    "        x_ = x_2\n",
    "\n",
    "        # Set certainty to 0 for off-image points\n",
    "        c_ = c1[x_[..., 0], x_[..., 1]]\n",
    "        c_[off_f] = 0\n",
    "\n",
    "        # Calculate A and delB for each point, according to paper\n",
    "        A = (A1 + A2[x_[..., 0], x_[..., 1]]) / 2\n",
    "        A *= c_[\n",
    "            ..., None, None\n",
    "        ]  # recommendation in paper: add in certainty by applying to A and delB\n",
    "\n",
    "        delB = -1 / 2 * (B2[x_[..., 0], x_[..., 1]] - B1) + (A @ d_[..., None])[..., 0]\n",
    "        delB *= c_[\n",
    "            ..., None\n",
    "        ]  # recommendation in paper: add in certainty by applying to A and delB\n",
    "\n",
    "        if mu == 0:\n",
    "            d = estimate_displacement_without_regularization(A, S_T, S, delB, w)\n",
    "        else:\n",
    "            d = estimate_displacement_with_regularization(A, S_T, S, delB, w, mu)\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_optical_flow_farneback(img1, img2):\n",
    "    assert img1.shape == img2.shape\n",
    "\n",
    "    n_pyr = 3\n",
    "    opts = dict(\n",
    "        sigma=4.0,\n",
    "        sigma_flow=4.0,\n",
    "        num_iter=3,\n",
    "        model=\"constant\",\n",
    "        mu=None,  # if mu is zero, there will be singularity error in linalg error. Use None and let it be computed automatically\n",
    "    )\n",
    "\n",
    "    d = None  # optical flow field\n",
    "\n",
    "    gaussion_pyramids = gen_gaussian_pyramids([img1, img2], n_pyr=n_pyr)\n",
    "    for pyr1, pyr2 in gaussion_pyramids:\n",
    "        if d is not None:\n",
    "            # TODO: account for shapes not quite matching\n",
    "            d = skimage.transform.pyramid_expand(d, channel_axis=-1)\n",
    "            d = d[: pyr1.shape[0], : pyr2.shape[1]] * 2\n",
    "\n",
    "        d = flow_iterative(pyr1, pyr2, d=d, **opts)\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(cv2.samples.findFile(\"input/snatch.mp4\"))  # 25 fps\n",
    "ret, frame1 = cap.read()\n",
    "prev = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "# prev: (1080, 1920) uint8 0 255\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[..., 1] = 255\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # Codec\n",
    "print(\"cap.get(cv2.CAP_PROP_FPS)\", cap.get(cv2.CAP_PROP_FPS))\n",
    "out = cv2.VideoWriter(\n",
    "    \"./output/snatch_optical_flow.mp4\",\n",
    "    fourcc,\n",
    "    fps=cap.get(cv2.CAP_PROP_FPS),\n",
    "    frameSize=(frame1.shape[1], frame1.shape[0]),\n",
    ")\n",
    "\n",
    "stop = 1\n",
    "while 1:\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret or stop == 0:\n",
    "        print(\"No frames grabbed!\")\n",
    "        break\n",
    "    next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    # next: (1080, 1920) uint8 0 255\n",
    "\n",
    "    flow = calc_optical_flow_farneback(prev, next)\n",
    "    # flow: (1080, 1920, 2) float64\n",
    "\n",
    "    bgr = my_utils.flow_to_color(flow, hsv)\n",
    "\n",
    "    # out.write(bgr)\n",
    "    cv2.imwrite(\"./output_farneback.png\", bgr)\n",
    "\n",
    "    # cv2.imshow(\"frame2\", bgr)\n",
    "    # k = cv2.waitKey(30) & 0xFF\n",
    "    # if k == 27:\n",
    "    #     break\n",
    "    # elif k == ord(\"s\"):\n",
    "    #     cv2.imwrite(\"opticalfb.png\", frame2)\n",
    "    #     cv2.imwrite(\"opticalhsv.png\", bgr)\n",
    "\n",
    "    prev = next\n",
    "    stop -= 1\n",
    "    print(\"stop: \", stop)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_computer_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
