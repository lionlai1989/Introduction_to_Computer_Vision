{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Filter for Object Tracking\n",
    "\n",
    "The particle filter is a general algorithm capable of addressing various problem types,\n",
    "with a particular strength in solving estimation problems. It excels in estimating the\n",
    "states of systems with _multimodal_ states, a task that conventional Kalman filters,\n",
    "including the _classic Kalman filter_, _extended Kalman filter_, and _unscented Kalman\n",
    "filter_, struggle to handle effectively. In this tutorial, I will explore the\n",
    "application of the particle filter for object tracking through two illustrative\n",
    "examples. The first example can be addressed using algorithms from the Kalman filter\n",
    "family, whereas the second problem demands the unique capabilities of the particle\n",
    "filter.\n",
    "\n",
    "**RULES:** As usual, **`OpenCV`** is banned in this repository.\n",
    "\n",
    "Please note that this tutorial will adhere to the notation used in the\n",
    "[Particle Filter's Wikipedia page](https://en.wikipedia.org/wiki/Particle_filter),\n",
    "ensuring that readers can easily refer to the source for additional information when\n",
    "needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import cv2\n",
    "import time\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from skimage import io, color\n",
    "from particle_filter_utils import *\n",
    "from functools import partial\n",
    "\n",
    "video_reader = imageio.get_reader(\"./input/pres_debate.avi\")\n",
    "frames = [np.array(frame) for frame in video_reader]\n",
    "video_reader.close()\n",
    "president_video = np.array(frames)\n",
    "assert president_video.ndim == 4  # n x H x W x 3\n",
    "\n",
    "video_reader = imageio.get_reader(\"./input/pedestrians.avi\")\n",
    "frames = [np.array(frame) for frame in video_reader]\n",
    "video_reader.close()\n",
    "blonde_video = np.array(frames)\n",
    "assert blonde_video.ndim == 4  # n x H x W x 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This tutorial focuses on the application of a particle filter for tracking objects over\n",
    "time. It's essential to clarify that we are specifically addressing a tracking problem,\n",
    "not a detection problem. In other words, our objective is not to detect an object but to\n",
    "track it once it's already known to us. To illustrate this, consider the scenario where\n",
    "we have initial information about a car's position, and our goal is to autonomously\n",
    "monitor and update the car's position continuously throughout a given time period.\n",
    "\n",
    "When tracking an object, the primary objective is to deduce a sequence of world states,\n",
    "denoted as $x_k$, from a noisy sequence of measurements or observations, denoted as\n",
    "$y_k$. Particle filters share similarities with Kalman filters, as they consist of two\n",
    "essential components: the dynamic or temporal model, denoted as $g(\\cdot)$, and the\n",
    "measurement model, denoted as $h(\\cdot)$.\n",
    "\n",
    "-   The dynamic or temporal model, $g(\\cdot)$, characterizes the relationship between\n",
    "    successive states. Typically, particle filters make use of the Markov assumption,\n",
    "    which posits that each state depends solely on its predecessor, represented as\n",
    "    $P(x_k | x_{k-1})$.\n",
    "\n",
    "-   The measurement model, $h(\\cdot)$, describes the connection between the measurement\n",
    "    $y_k$ and the state $x_k$ at time $k$. We consider this model as generative, and it\n",
    "    helps us model the likelihood, $P(y_k | x_k)$.\n",
    "\n",
    "By leveraging this statistical dependency, we can infer the state, $x_k$, even when the\n",
    "associated observation, $y_k$, provides partial or no informative content.\n",
    "\n",
    "In the context of inference, the primary challenge is to calculate the marginal\n",
    "posterior distribution:\n",
    "\n",
    "$$\n",
    "P(x_k|y_{0\\dots k}) = \\frac{P(y_k|x_k)P(x_k|y_{0\\dots {k-1}})}{\\int P(y_k|x_k)\n",
    "P(x_k|y_{0 \\dots {k-1}}) dx}\n",
    "$$\n",
    "\n",
    "To evaluate $P(x_k | y_{0\\dots k})$, we need to determine $P(x_k | y_{0\\dots {k-1}})$,\n",
    "which signifies our prior knowledge about the state $x_k$ before incorporating the\n",
    "associated measurement $y_k$. This can be computed as follows:\n",
    "\n",
    "$$\n",
    "P(x_k|y_{0 \\dots k-1}) = \\int P(x_k|x_{k-1}) P(x_{k-1}|y_{0 \\dots {k-1}}) dx_{k-1}\n",
    "$$\n",
    "\n",
    "One of the simplest particle filter methods is the _conditional density propagation_ or\n",
    "_condensation_ algorithm. In this algorithm, the probability distribution\n",
    "$P(x_k|y_{0\\dots k-1})$ is represented by a weighted sum of particles. The following\n",
    "intuitive image provides an overview of how the condensation algorithm works:\n",
    "\n",
    "a) The posterior at the previous step is represented as a set of weighted particles.\n",
    "\n",
    "b) The particles are resampled according to their weights to produce a new set of\n",
    "unweighted particles.\n",
    "\n",
    "c) These particles are passed through the nonlinear temporal function.\n",
    "\n",
    "d) Noise is added according to the temporal model.\n",
    "\n",
    "e) The particles are passed through the measurement model and compared to the\n",
    "measurement density.\n",
    "\n",
    "f) The particles are re-weighted according to their compatibility with the measurements,\n",
    "and the process can begin again.\n",
    "\n",
    "<img src=\"./images/Particle.svg\" alt=\"Alternative Text\">\n",
    "\n",
    "The image and the accompanying description provided above have been adapted from the\n",
    "[book](http://www.computervisionmodels.com/) \"Computer Vision: Models, Learning, and\n",
    "Inference\" authored by Simon J. D. Prince.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navie Particle Filter\n",
    "\n",
    "After providing an overview of our objective, let's delve into the specific details of\n",
    "our task. To begin, it's crucial to establish the definition of our \"model\" or\n",
    "\"template\" within this context. The \"model\" or \"template\" represents the object that we\n",
    "aim to track. This entity could manifest as a patch in an image, a contour, or any other\n",
    "descriptive representation of the object under consideration.\n",
    "\n",
    "For the first task, we need to track a patch taken from the first frame of the video as\n",
    "shown below, which is Mitt Romney's face. Our goal is to track this face throughout the\n",
    "time. Thus we can define a `Template` which holds the information of the template as\n",
    "follow:\n",
    "\n",
    "```python\n",
    "class Template:\n",
    "    def __init__(self, img, x, y, w, h) -> None:\n",
    "        self.x = int(x)\n",
    "        self.y = int(y)\n",
    "        self.w = int(w)\n",
    "        self.h = int(h)\n",
    "        self.model = img[self.y : self.y + self.h, self.x : self.x + self.w, ...]\n",
    "```\n",
    "\n",
    "Once we've established our template, it naturally leads to the design of the system's\n",
    "state, which comprises the following four components: `(x, y, w, h)`. These components\n",
    "represent the x-axis coordinate `x`, the y-axis coordinate `y`, the width of the window\n",
    "`w`, and the height of the window `h`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_frame = president_video[0, ...]  # NOTE: uint8. 0-255.\n",
    "print(\"first_frame: \", first_frame.shape)\n",
    "x, y, w, h = 320, 175, 103, 129\n",
    "template = Template(first_frame, x, y, w, h)\n",
    "print(\n",
    "    \"template.model:\",\n",
    "    \"shape:\", template.model.shape,\n",
    "    \"type:\", template.model.dtype,\n",
    "    \"min:\", np.min(template.model),\n",
    "    \"max:\", np.max(template.model),\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 2))  # Adjust the figure size as needed\n",
    "plt.axis(\"off\")\n",
    "ax.imshow(template.model)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Model\n",
    "\n",
    "Now that we have defined our system's state, we can proceed to define our dynamic\n",
    "system. In this straightforward particle filter, we opt for the simplest form of motion,\n",
    "known as Brownian motion:\n",
    "\n",
    "$$\n",
    "x_{k} = x_{t-1} + W_{k-1}\n",
    "$$\n",
    "\n",
    "The process noise represented by $W_{k-1}$ introduces variability in our dynamic model.\n",
    "It's important to note that the range and magnitude of each dimension in the state and\n",
    "the associated process noise can differ. For instance, when considering `x` and `y`,\n",
    "these dimensions should remain within the boundaries of the image's dimensions.\n",
    "Consequently, the standard deviation of their process noise should typically fall within\n",
    "the range of 10 to 50. On the other hand, `w` and `h` should fall within an anticipated\n",
    "range, typically around 10 to 25 pixels added or subtracted from the original patch\n",
    "size. This choice is made based on practical considerations, as we wouldn't expect an\n",
    "object, such as Mitt Romney's face, to occupy the entire image. Hence, the standard\n",
    "deviation of the process noise of `w` and `h` should be only few pixels.\n",
    "\n",
    "The choice of using Brownian motion as the dynamic model is grounded in the absence of\n",
    "external control inputs to govern the object being tracked. In such scenarios, we can\n",
    "assume that the object's movement is inherently random. The implementation is\n",
    "straightforward, as outlined below. Essentially, during the prediction step, we\n",
    "introduce Gaussian noise to the state vector. You might wonder about the magnitude of\n",
    "noise added to the state. The magnitude varies depending on the specific state\n",
    "dimension. For instance, if we have prior knowledge that the object in the image\n",
    "typically moves only a few pixels in each time step, an appropriate value might range\n",
    "from a sub ten to tens of pixels. It's important to note that in our task, we must\n",
    "constrain the boundaries of the state, as it wouldn't be logical for image coordinates,\n",
    "for example, to be negative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicModel:\n",
    "    def __init__(self, std: List) -> None:\n",
    "        self.std = std\n",
    "        self.num_states = len(std)\n",
    "\n",
    "    def predict(self, particles: np.ndarray, state_boundry: List[Tuple]):\n",
    "        for i in range(self.num_states):\n",
    "            # Brownian motion.\n",
    "            particles[:, i] += np.random.normal(\n",
    "                loc=0, scale=self.std[i], size=particles[:, i].shape\n",
    "            )  # Modify particles in-place\n",
    "\n",
    "            lower_bound, upper_bound = state_boundry[i]\n",
    "\n",
    "            # Constrain state within boundry.\n",
    "            np.clip(particles[:, i], lower_bound, upper_bound, out=particles[:, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measurement Model\n",
    "\n",
    "now let's talk about measurement model. the measurement model is a bit more complicate\n",
    "than dynamic model because observation data is all we have to correct the state.\n",
    "\n",
    "there are many things needed to be taken care of:\n",
    "\n",
    "-   measurement function: the measure function is:\n",
    "\n",
    "$$\n",
    "p(z|x) = e^{\\frac{-distance}{2*\\sigma}}\n",
    "$$\n",
    "\n",
    "the distance here is always positive, thus the expression $e^{-x}$ is always between 0\n",
    "and 1, which can be quite useful and handful. the $\\sigma$ is the standard deviation we\n",
    "want to credit our observation data. The bigger std, the more uncertain we are about the\n",
    "observation data. the smaller std, we can put more trust on the observation data. now,\n",
    "what's tricky is that can we use a universal sigma for different kinds of distance\n",
    "functions. I've tried three distance functions here, mean squared error, chi squared and\n",
    "cosine similarity. I don't know why consine similariyt performs kind of wonky here,\n",
    "since I think cosine similarity can also measure the similarity of two image patches.\n",
    "mse and chi-squared both work. to my surprice, mse is actually performing better than\n",
    "chi-squared and it's more computation efficient. the weight is 0 if their size doesn't\n",
    "match or they are very different. The weight is 1 if they are exactly the same.\n",
    "\n",
    "-   Get windows corresponding to each particle. For each particle, it has 4 states, x\n",
    "    coord., y coord. width and height. We want to use (x, y, w, h) to crop a window from\n",
    "    the given frame. two things need to be handle here. One, even though we have\n",
    "    constrained states minimum and maximum value in the resampling stage, we still can\n",
    "    not guarantee that (x, y, w, h) is a valid window. If we want to guarantee that (x,\n",
    "    y, w, h) must be a valid window, we must also constained the relationship between x\n",
    "    and w, y and h. However, it's not necessary. because in the later step, we can just\n",
    "    reset the weight of the particle to 0 if the window is invalid.\n",
    "\n",
    "    the second thing to notice is that the cropped window has the different size as the\n",
    "    template, so we must resize the window to match template's size.\n",
    "\n",
    "    the last thing is normalizing the weight so they sum to 1.\n",
    "\n",
    "-   update_template: when tracking an target, the target appearance could change over\n",
    "    time, thus we must also update our template over time. updating the template can be\n",
    "    achieve with the eqaution:\n",
    "\n",
    "    $$\n",
    "    template = \\alpha * state + (1 - \\alpha) * template\n",
    "    $$\n",
    "\n",
    "    updating template is the process of fusion latest state and history states. now we\n",
    "    don't want to always update the latest state because the latest state may be broken.\n",
    "    so we must be cautious.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeasurementModel:\n",
    "    def __init__(self, std, template, distance_func, alpha=0.0) -> None:\n",
    "        self.std = std\n",
    "        self.template = template\n",
    "        self.distance_func = distance_func\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def measure(self, particles, frame):\n",
    "        num_particles = particles.shape[0]\n",
    "        # Get windows corresponding to each particle\n",
    "        # Fix the size of template and resize each particle to match template\n",
    "        template_width, template_height = self.template.w, self.template.h\n",
    "        artificial_measurements = []\n",
    "        for i in range(num_particles):\n",
    "            x = particles[i, 0]  # float\n",
    "            y = particles[i, 1]  # float\n",
    "            w = particles[i, 2]  # float\n",
    "            h = particles[i, 3]  # float\n",
    "            start_y = int(y - h / 2)\n",
    "            start_x = int(x - w / 2)\n",
    "            end_y = int(start_y + h)\n",
    "            end_x = int(start_x + w)\n",
    "            # print(\n",
    "            #     f\"x: {x}, y: {y}, w: {w}, h: {h}, start_y: {start_y}, start_x: {start_x}, end_y: {end_y}, end_x: {end_x}\"\n",
    "            # )\n",
    "            temp = frame[start_y:end_y, start_x:end_x, :]\n",
    "            if temp.size == 0:\n",
    "                # it's ok to still add it because the weight is reset as 0 in the latter process.\n",
    "                artificial_measurements.append(temp)\n",
    "            else:\n",
    "                resized_image = cv2.resize(temp, (template_width, template_height))\n",
    "                artificial_measurements.append(resized_image)\n",
    "\n",
    "        # NOTE: Add measurement noise? window += np.random.normal(loc=0, scale=self.std, size=window.shape).astype(np.uint8)\n",
    "        # Compute importance weight: Measuring similarity of each window to the template\n",
    "        weights = []  # FIXME: Use array broadcasting\n",
    "        for m in artificial_measurements:\n",
    "            weights.append(self.measure_function(m, self.template.model))\n",
    "        weights = np.array(weights)\n",
    "\n",
    "        # NOTE: WE may want to clip weight here. eg, weight[weight<1e-3] = 0\n",
    "        # so that particles with very small weight can have zero chances.\n",
    "        # weights *= 1000\n",
    "        # weights[weights < 1e-3] = 0\n",
    "        # Normalize the weights\n",
    "        weights /= np.sum(weights)\n",
    "        return weights\n",
    "\n",
    "    def measure_function(self, window, template):\n",
    "        if window.shape != template.shape:\n",
    "            # NOTE: This statement must be here. It can not be put into distance function.\n",
    "            return 0\n",
    "        dist = self.distance_func(window, template)\n",
    "        weight = np.exp(-dist / (2 * self.std**2))\n",
    "\n",
    "        return weight\n",
    "\n",
    "    def update_template(self, frame, state):\n",
    "        x = state[0]\n",
    "        y = state[1]\n",
    "        w = state[2]\n",
    "        h = state[3]\n",
    "        start_x = int(x - w / 2)\n",
    "        start_y = int(y - h / 2)\n",
    "        end_x = int(start_x + w)\n",
    "        end_y = int(start_y + h)\n",
    "        best_model = frame[start_y:end_y, start_x:end_x, ...]\n",
    "\n",
    "        # resize current to best model bcs the best model shrinks.\n",
    "        resized_template = cv2.resize(self.template.model, (w, h))\n",
    "        # assert resized_template.shape == best_model.shape, f\"x: {x}, y: {y}, w: {w}, h: {h}, resized_template: {resized_template.shape}, best_model: {best_model.shape}\"\n",
    "\n",
    "        if resized_template.shape != best_model.shape:\n",
    "            return\n",
    "\n",
    "        self.template.model = (\n",
    "            self.alpha * best_model + (1 - self.alpha) * resized_template\n",
    "        )\n",
    "        # self.template.model = self.template.model.astype(np.uint8)\n",
    "\n",
    "        # update x, y, w, h\n",
    "        self.template.x = x\n",
    "        self.template.y = y\n",
    "        self.template.w = w\n",
    "        self.template.h = h\n",
    "\n",
    "\n",
    "def mean_squared_error(window, template):\n",
    "    mse = np.sum(np.subtract(window, template, dtype=np.float64) ** 2)\n",
    "    mse /= float(window.shape[0] * window.shape[1])\n",
    "    return mse\n",
    "\n",
    "\n",
    "def cosine_similarity(window, template):\n",
    "    gray_window, gray_template = color.rgb2gray(window), color.rgb2gray(template)\n",
    "    gray_window *= 255\n",
    "    gray_template *= 255\n",
    "    dividend = np.sum(np.multiply(gray_window, gray_template))\n",
    "    divisor = np.multiply(\n",
    "        np.sqrt(np.sum(gray_window**2)), np.sqrt(np.sum(gray_template**2))\n",
    "    )\n",
    "    assert np.all(divisor != 0), f\"divisor has 0 in it. {divisor}\"\n",
    "    tmp = (np.divide(dividend, divisor) + 1) / 10000\n",
    "    assert tmp > 0\n",
    "    return tmp\n",
    "    # dividend = np.sum(np.multiply(window, template))\n",
    "    # divisor = np.multiply(np.sqrt(np.sum(window**2)), np.sqrt(np.sum(template**2)))\n",
    "    # assert np.all(divisor != 0), f\"divisor has 0 in it. {divisor}\"\n",
    "    # return 0.5 * (np.divide(dividend, divisor) + 1)\n",
    "\n",
    "\n",
    "def chi_squared(window, template, num_bins=8):\n",
    "    # Compute histograms for each channel\n",
    "    hist1 = []\n",
    "    hist2 = []\n",
    "    for channel in range(window.shape[2]):\n",
    "        hist1_channel, _ = np.histogram(\n",
    "            window[:, :, channel], bins=num_bins, range=(0, 256)\n",
    "        )\n",
    "        hist2_channel, _ = np.histogram(\n",
    "            template[:, :, channel], bins=num_bins, range=(0, 256)\n",
    "        )\n",
    "\n",
    "        # Normalize the histograms\n",
    "        # hist1_channel = hist1_channel.astype(np.float64)\n",
    "        # hist2_channel = hist2_channel.astype(np.float64)\n",
    "        # hist1_channel /= hist1_channel.sum() + 1e-10\n",
    "        # hist2_channel /= hist2_channel.sum() + 1e-10\n",
    "\n",
    "        hist1.append(hist1_channel)\n",
    "        hist2.append(hist2_channel)\n",
    "\n",
    "    hist1 = np.array(hist1)\n",
    "    hist2 = np.array(hist2)\n",
    "\n",
    "    # Compute the Chi-Squared distance\n",
    "    chi_squared_distance = np.sum(((hist1 - hist2) ** 2) / (hist1 + hist2 + 1e-10))\n",
    "    return chi_squared_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Particle Filter\n",
    "\n",
    "talk about update template, reset,\n",
    "\n",
    "**num_states**: the number of states in the naive particle filter\n",
    "**state_boundry**: for each state, it has a boundry.\n",
    "**num_particles**: the number of particles in the navie particle filter.\n",
    "**consensus**: it is from 0 to 1 used to represent a proportion of particles with larget\n",
    "weights which will be used to determine some matter. It uses minor meritocraciy. only\n",
    "top-tier weights have a say. if `consensus=0.05` and `num_particles=500`, then only\n",
    "`0.05*500=25` particles with highest weights will be selected.\n",
    "\n",
    "**upper_thres**: once elite particles have been selected, their sum must be higher than\n",
    "a certain value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveParticleFilter:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_states: int,\n",
    "        state_boundry: List[Tuple],\n",
    "        dynamic_model: DynamicModel,\n",
    "        measure_model: MeasurementModel,\n",
    "        num_particles=100,\n",
    "        consensus=0.05,  # percentage\n",
    "        upper_thres=0.3,  # percentage\n",
    "        lower_thres=0.1,  # percentage\n",
    "    ):\n",
    "        self.num_states = num_states\n",
    "        self.state_boundry = state_boundry\n",
    "        self.num_particles = num_particles\n",
    "        self.dynamic_model = dynamic_model\n",
    "        self.measure_model = measure_model\n",
    "        # Democracy here.\n",
    "        self.num_consensus_particles = int(self.num_particles * consensus)\n",
    "        self.upper_thres = upper_thres\n",
    "        self.lower_thres = lower_thres\n",
    "\n",
    "        self.particles = np.zeros((num_particles, num_states))  # (N, 4): x, y, w, h\n",
    "        self.weights = np.ones(self.num_particles) / self.num_particles  # (N, ): weight\n",
    "\n",
    "        self.reset_particles()\n",
    "        self.state = self.particles[69, :] # Initialize state randomly\n",
    "\n",
    "    def reset_particles(self):\n",
    "        for i in range(self.num_states):\n",
    "            lower_bound, upper_bound = self.state_boundry[i]\n",
    "            self.particles[:, i] = np.random.uniform(\n",
    "                lower_bound, upper_bound, self.num_particles\n",
    "            )\n",
    "        # Rest weights. each particle has the same weight.\n",
    "        self.weights = np.ones(self.num_particles) / self.num_particles\n",
    "\n",
    "    def update(self, frame):\n",
    "        sorted_indices = np.argsort(self.weights)\n",
    "        largest_indices = sorted_indices[-self.num_consensus_particles :]\n",
    "        # if (\n",
    "        #     np.sum(self.weights[largest_indices])\n",
    "        #     >  self.lower_thres\n",
    "        # ):\n",
    "        self.resample_particles()\n",
    "        \n",
    "        self.dynamic_model.predict(self.particles, self.state_boundry)\n",
    "\n",
    "        self.weights = self.measure_model.measure(self.particles, frame)\n",
    "\n",
    "        # Add very certain here\n",
    "\n",
    "        # NOTE: MAYBE not always update states. think about occlusion.\n",
    "        self.update_states()\n",
    "\n",
    "        if np.sum(self.weights[largest_indices]) > self.upper_thres:\n",
    "            self.measure_model.update_template(frame, self.state)\n",
    "\n",
    "        # if np.sum(self.weights[largest_indices]) < self.lower_thres:\n",
    "        #     # reset particles is kind of stupid. it destroys all prior info.\n",
    "        #     self.reset_particles()\n",
    "\n",
    "    def resample_particles(self):\n",
    "        # sample new particle indices using the distribution of the weights\n",
    "        j = np.random.choice(\n",
    "            np.arange(self.num_particles),\n",
    "            self.num_particles,\n",
    "            replace=True,\n",
    "            p=self.weights,\n",
    "        )\n",
    "\n",
    "        # get a random control input from a normal distribution\n",
    "        # sample the particles using the distribution of the weights\n",
    "        self.particles = np.array(self.particles[j])\n",
    "        assert self.particles.shape[0] == self.num_particles\n",
    "\n",
    "        # clip particles in case the window goes out of the image limits\n",
    "        for i in range(self.num_states):\n",
    "            lower_bound, upper_bound = self.state_boundry[i]\n",
    "            np.clip(\n",
    "                self.particles[:, i], lower_bound, upper_bound, out=self.particles[:, i]\n",
    "            )\n",
    "\n",
    "        # Rest weights. each particle has the same weight.\n",
    "        self.weights = np.ones(self.num_particles) / self.num_particles\n",
    "\n",
    "    def update_states(self):\n",
    "        sorted_indices = np.argsort(self.weights)\n",
    "        largest_indices = sorted_indices[-self.num_consensus_particles :]\n",
    "        s = np.sum(self.particles[largest_indices, :], axis=0)\n",
    "        average = s / len(largest_indices)\n",
    "        self.state = average.astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navie example \n",
    "frame = (720, 1280, 3)\n",
    "in this example, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = [(mean_squared_error, 16, 16, 0.01, 2), (chi_squared, 16, 16, 0.01, 2)]\n",
    "\n",
    "tracker = NaiveParticleFilter(\n",
    "    num_states=4,\n",
    "    state_boundry=[\n",
    "        (0, first_frame.shape[1] - 1),\n",
    "        (0, first_frame.shape[0] - 1),\n",
    "        (100, 105),\n",
    "        (125, 135),\n",
    "    ],\n",
    "    dynamic_model=DynamicModel(std=(16, 16, 0.5, 0.5)),\n",
    "    measure_model=MeasurementModel(\n",
    "        std=16,\n",
    "        template=template,\n",
    "        distance_func=partial(mean_squared_error),\n",
    "        # distance_func=partial(chi_squared, num_bins=12),\n",
    "        # distance_func=partial(cosine_similarity),\n",
    "        alpha=0.01,\n",
    "    ),\n",
    "    num_particles=128,\n",
    "    consensus=0.20,  # percentage\n",
    "    upper_thres=0.2,  # percentage\n",
    "    lower_thres=0.1,  # percentage\n",
    ")\n",
    "\n",
    "for i in range(1, president_video.shape[0]):\n",
    "    start_time = time.time()\n",
    "\n",
    "    frame = president_video[i, ...]\n",
    "\n",
    "    tracker.update(frame)\n",
    "\n",
    "    frame = visualize_particle_filter(\n",
    "        frame, tracker.particles, tracker.state, tracker.measure_model.template\n",
    "    )\n",
    "\n",
    "    delay = int(25 - (time.time() - start_time))\n",
    "    if cv2.waitKey(delay) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "    cv2.imshow(\"pres_debate\", frame[:, :, ::-1])  # Display the resulting frame\n",
    "    # ax.imshow(frame)\n",
    "    # display(fig)\n",
    "    # clear_output(wait=True)\n",
    "    # time.sleep(1)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DynamicModel:\n",
    "#     def __init__(self, std) -> None:\n",
    "#         self.std = std\n",
    "\n",
    "#     def predict(self, particles):\n",
    "#         # The simplest dyanmic model is brownian motion.\n",
    "#         particles += np.random.normal(loc=0, scale=self.std, size=particles.shape)\n",
    "\n",
    "\n",
    "# class MeasurementModel:\n",
    "#     def __init__(self, std, template, distance_func, alpha=0.0, update_thres=2) -> None:\n",
    "#         self.std = std\n",
    "#         self.template = template\n",
    "#         self.distance_func = distance_func\n",
    "#         self.alpha = alpha\n",
    "#         self.update_thres = update_thres\n",
    "\n",
    "#     def measure(self, particles, frame):\n",
    "#         num_particles = particles.shape[0]\n",
    "#         # Get windows corresponding to each particle\n",
    "#         win_height, win_width = self.template.model.shape[:2]\n",
    "#         start_x = (particles[:, 0] - win_width / 2).astype(int)\n",
    "#         start_y = (particles[:, 1] - win_height / 2).astype(int)\n",
    "#         end_x = start_x + win_width\n",
    "#         end_y = start_y + win_height\n",
    "\n",
    "#         artificial_measurements = []\n",
    "#         for i in range(num_particles):\n",
    "#             window = frame[start_y[i] : end_y[i], start_x[i] : end_x[i]]\n",
    "#             # NOTE: Add measurement noise? window += np.random.normal(loc=0, scale=self.std, size=window.shape).astype(np.uint8)\n",
    "#             artificial_measurements.append(window)\n",
    "\n",
    "#         # Compute importance weight: Measuring similarity of each window to the template\n",
    "#         weights = []\n",
    "#         for m in artificial_measurements:\n",
    "#             weights.append(self.measure_function(m, self.template.model))\n",
    "#         weights = np.array(weights)\n",
    "\n",
    "#         # Normalize the weights\n",
    "#         weights /= np.sum(weights)\n",
    "\n",
    "#         # Only update template if very certain.\n",
    "#         best_index = np.argmax(weights)\n",
    "#         if weights[best_index] > self.update_thres * 1 / num_particles:\n",
    "#             self.update_template(frame, particles[best_index, :])\n",
    "\n",
    "#         return weights\n",
    "\n",
    "#     def measure_function(self, window, template):\n",
    "#         if window.shape != template.shape:\n",
    "#             # NOTE: This statement must be here. It can not be put into distance function.\n",
    "#             return 0\n",
    "#         dist = self.distance_func(window, template)\n",
    "#         return np.exp(-dist / (2 * self.std**2))\n",
    "\n",
    "#     def update_template(self, frame, states):\n",
    "#         w = self.template.w\n",
    "#         h = self.template.h\n",
    "#         x = int(states[0] - w / 2)\n",
    "#         y = int(states[1] - h / 2)\n",
    "#         best_model = frame[y : y + h, x : x + w]\n",
    "#         if best_model.shape == self.template.model.shape:\n",
    "#             self.template.model = (\n",
    "#                 self.alpha * best_model + (1 - self.alpha) * self.template.model\n",
    "#             )\n",
    "#             # self.template.model = self.template.model.astype(np.uint8)\n",
    "\n",
    "\n",
    "# def mean_squared_error(window, template):\n",
    "#     mse = np.sum(np.subtract(window, template, dtype=np.float64) ** 2)\n",
    "#     mse /= float(window.shape[0] * window.shape[1])\n",
    "#     return mse\n",
    "\n",
    "\n",
    "# def cosine_similarity(window, template):\n",
    "#     gray_window, gray_template = color.rgb2gray(window), color.rgb2gray(template)\n",
    "#     gray_window *= 255\n",
    "#     gray_template *= 255\n",
    "#     dividend = np.sum(np.multiply(gray_window, gray_template))\n",
    "#     divisor = np.multiply(\n",
    "#         np.sqrt(np.sum(gray_window**2)), np.sqrt(np.sum(gray_template**2))\n",
    "#     )\n",
    "#     assert np.all(divisor != 0), f\"divisor has 0 in it. {divisor}\"\n",
    "#     tmp = (np.divide(dividend, divisor)+1) / 10000\n",
    "#     assert tmp > 0\n",
    "#     return tmp\n",
    "#     # dividend = np.sum(np.multiply(window, template))\n",
    "#     # divisor = np.multiply(np.sqrt(np.sum(window**2)), np.sqrt(np.sum(template**2)))\n",
    "#     # assert np.all(divisor != 0), f\"divisor has 0 in it. {divisor}\"\n",
    "#     # return 0.5 * (np.divide(dividend, divisor) + 1)\n",
    "\n",
    "\n",
    "# def chi_squared(window, template, num_bins=8):\n",
    "#     # Compute histograms for each channel\n",
    "#     hist1 = []\n",
    "#     hist2 = []\n",
    "#     for channel in range(window.shape[2]):\n",
    "#         hist1_channel, _ = np.histogram(\n",
    "#             window[:, :, channel], bins=num_bins, range=(0, 256)\n",
    "#         )\n",
    "#         hist2_channel, _ = np.histogram(\n",
    "#             template[:, :, channel], bins=num_bins, range=(0, 256)\n",
    "#         )\n",
    "\n",
    "#         # Normalize the histograms\n",
    "#         # hist1_channel = hist1_channel.astype(np.float64)\n",
    "#         # hist2_channel = hist2_channel.astype(np.float64)\n",
    "#         # hist1_channel /= hist1_channel.sum() + 1e-10\n",
    "#         # hist2_channel /= hist2_channel.sum() + 1e-10\n",
    "\n",
    "#         hist1.append(hist1_channel)\n",
    "#         hist2.append(hist2_channel)\n",
    "\n",
    "#     hist1 = np.array(hist1)\n",
    "#     hist2 = np.array(hist2)\n",
    "\n",
    "#     # Compute the Chi-Squared distance\n",
    "#     chi_squared_distance = np.sum(((hist1 - hist2) ** 2) / (hist1 + hist2 + 1e-10))\n",
    "#     return chi_squared_distance\n",
    "    \n",
    "\n",
    "# class NaiveParticleFilter:\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         search_height,\n",
    "#         search_width,\n",
    "#         dynamic_model: DynamicModel,\n",
    "#         measure_model: MeasurementModel,\n",
    "#         num_particles=100,\n",
    "#         consensus=20, # percentage\n",
    "#     ):\n",
    "#         self.search_height = search_height\n",
    "#         self.search_width = search_width\n",
    "#         self.num_particles = num_particles\n",
    "#         self.dynamic_model = dynamic_model\n",
    "#         self.measure_model = measure_model\n",
    "#         self.num_consensus_particles = int(self.num_particles / consensus)\n",
    "\n",
    "#         particles = []\n",
    "#         for x, y in zip(\n",
    "#             np.random.uniform(0, self.search_width, self.num_particles),\n",
    "#             np.random.uniform(0, self.search_height, self.num_particles),\n",
    "#         ):\n",
    "#             particles.append((x, y))\n",
    "\n",
    "#         self.particles = np.array(particles)  # (N, 2): x, y\n",
    "#         self.weights = np.ones(self.num_particles) / self.num_particles  # (N, ): weight\n",
    "#         self.states = self.particles[0, :]\n",
    "\n",
    "#     def update(self, frame):\n",
    "#         self.resample_particles()\n",
    "#         self.dynamic_model.predict(self.particles)\n",
    "#         self.weights = self.measure_model.measure(self.particles, frame)\n",
    "#         self.update_states()\n",
    "\n",
    "#     def resample_particles(self):\n",
    "#         sw, sh = self.search_width, self.search_height\n",
    "\n",
    "#         # sample new particle indices using the distribution of the weights\n",
    "#         j = np.random.choice(\n",
    "#             np.arange(self.num_particles),\n",
    "#             self.num_particles,\n",
    "#             replace=True,\n",
    "#             p=self.weights,\n",
    "#         )\n",
    "#         # get a random control input from a normal distribution\n",
    "#         # sample the particles using the distribution of the weights\n",
    "#         self.particles = np.array(self.particles[j])\n",
    "#         assert self.particles.shape[0] == self.num_particles\n",
    "#         # clip particles in case the window goes out of the image limits\n",
    "#         self.particles[:, 0] = np.clip(self.particles[:, 0], 0, sw - 1)\n",
    "#         self.particles[:, 1] = np.clip(self.particles[:, 1], 0, sh - 1)\n",
    "\n",
    "#         # Rest weights. each particle has the same weight.\n",
    "#         self.weights = np.ones(self.num_particles) / self.num_particles\n",
    "\n",
    "#     def update_states(self):\n",
    "#         best_index = np.argmax(self.weights)\n",
    "#         self.states = self.particles[best_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch = president_video[0, ...]  # NOTE: uint8. 0-255.\n",
    "# x, y, w, h = 320.8751, 175.1776, 103.5404, 129.0504\n",
    "# template = Template(patch, x, y, w, h)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(6, 4))  # Adjust the figure size as needed\n",
    "# plt.axis(\"off\")\n",
    "# ax.imshow(template.model)\n",
    "# plt.show()\n",
    "# print(\n",
    "#     \"template.model: \",\n",
    "#     template.model.shape,\n",
    "#     template.model.dtype,\n",
    "#     np.min(template.model),\n",
    "#     np.max(template.model),\n",
    "# )\n",
    "\n",
    "# parameter = [(mean_squared_error, 16, 16, 0.01, 2), (chi_squared, 16, 16, 0.01, 2)]\n",
    "\n",
    "# tracker = NaiveParticleFilter(\n",
    "#     patch.shape[1],  # can be replace with template\n",
    "#     patch.shape[0],\n",
    "#     DynamicModel(std=16),\n",
    "#     MeasurementModel(\n",
    "#         std=16,\n",
    "#         template=template,\n",
    "#         distance_func=mean_squared_error,\n",
    "#         # distance_func=partial(chi_squared, num_bins=12),\n",
    "#         # distance_func=cosine_similarity,\n",
    "#         alpha=0.2,\n",
    "#         update_thres=2,\n",
    "#     ),\n",
    "#     num_particles=100,\n",
    "# )\n",
    "\n",
    "# for i in range(1, president_video.shape[0]):\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     frame = president_video[i, ...]\n",
    "\n",
    "#     tracker.update(frame)\n",
    "\n",
    "#     frame = visualize_particle_filter(\n",
    "#         frame, tracker.particles, tracker.states, tracker.measure_model.template\n",
    "#     )\n",
    "\n",
    "#     delay = int(25 - (time.time() - start_time))\n",
    "#     if cv2.waitKey(delay) & 0xFF == ord(\"q\"):\n",
    "#         break\n",
    "#     cv2.imshow(\"pres_debate\", frame[:, :, ::-1])  # Display the resulting frame\n",
    "#     # ax.imshow(frame)\n",
    "#     # display(fig)\n",
    "#     # clear_output(wait=True)\n",
    "#     # time.sleep(1)\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_file = \"./images/romney.mp4\"\n",
    "\n",
    "# video_writer = imageio.get_writer(output_file, fps=30)  # You can adjust the FPS as needed\n",
    "# for frame in final_output:\n",
    "#     video_writer.append_data(frame)\n",
    "\n",
    "# # Close the video writer\n",
    "# video_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More realworld example\n",
    "\n",
    "frame is (360, 480, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### dynamic model\n",
    "\n",
    "### measurement model\n",
    "\n",
    "### Read world particle filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch = blonde_video[0, ...]\n",
    "# x, y, w, h = 211.0000, 36.0000, 100.0000, 293.0000\n",
    "# template = Template(patch, x, y, w, h)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(6, 4))  # Adjust the figure size as needed\n",
    "# plt.axis(\"off\")\n",
    "# ax.imshow(template.model)\n",
    "# plt.show()\n",
    "# print(\n",
    "#     \"template.model: \",\n",
    "#     template.model.shape,\n",
    "#     template.model.dtype,\n",
    "#     np.min(template.model),\n",
    "#     np.max(template.model),\n",
    "# )\n",
    "\n",
    "\n",
    "# tracker = NaiveParticleFilter(\n",
    "#     patch.shape[1],\n",
    "#     patch.shape[0],\n",
    "#     DynamicModel(std=10),\n",
    "#     MeasurementModel(\n",
    "#         std=10,\n",
    "#         template=template,\n",
    "#         measure_func=partial(mean_squared_error, mse_std=100),\n",
    "#         # measure_func=partial(chi_squared, num_bins=16),\n",
    "#         # measure_func=partial(cosine_similarity),\n",
    "#         alpha=0.0075,\n",
    "#     ),\n",
    "#     num_particles=100,\n",
    "# )\n",
    "\n",
    "# for i in range(1, blonde_video.shape[0]):\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     frame = blonde_video[i, ...]\n",
    "\n",
    "#     tracker.update(frame)\n",
    "\n",
    "#     frame = visualize_particle_filter(\n",
    "#         frame, tracker.particles, tracker.states, tracker.measure_model.template\n",
    "#     )\n",
    "\n",
    "#     delay = int(25 - (time.time() - start_time))\n",
    "#     if cv2.waitKey(delay) & 0xFF == ord(\"q\"):\n",
    "#         break\n",
    "#     cv2.imshow(\"pres_debate\", frame[:, :, ::-1])  # Display the resulting frame\n",
    "#     # ax.imshow(frame)\n",
    "#     # display(fig)q\n",
    "#     # clear_output(wait=True)\n",
    "#     # time.sleep(1)\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_frame = blonde_video[0, ...]  # NOTE: uint8. 0-255.\n",
    "print(\"first_frame: \", first_frame.shape)\n",
    "x, y, w, h = 211, 36, 100, 293\n",
    "template = Template(first_frame, x, y, w, h)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3, 2))  # Adjust the figure size as needed\n",
    "plt.axis(\"off\")\n",
    "ax.imshow(template.model)\n",
    "plt.show()\n",
    "print(\n",
    "    \"template.model: \",\n",
    "    template.model.shape,\n",
    "    template.model.dtype,\n",
    "    np.min(template.model),\n",
    "    np.max(template.model),\n",
    ")\n",
    "\n",
    "parameter = [(mean_squared_error, 16, 16, 0.01, 2), (chi_squared, 16, 16, 0.01, 2)]\n",
    "\n",
    "tracker = NaiveParticleFilter(\n",
    "    num_states=4,\n",
    "    state_boundry=[\n",
    "        (0, first_frame.shape[1] - 1),\n",
    "        (0, first_frame.shape[0] - 1),\n",
    "        (10, 100),\n",
    "        (20, 290),\n",
    "    ],\n",
    "    dynamic_model=DynamicModel(std=(16, 16, 1, 1)),\n",
    "    measure_model=MeasurementModel(\n",
    "        std=16,\n",
    "        template=template,\n",
    "        distance_func=mean_squared_error,\n",
    "        # distance_func=partial(chi_squared, num_bins=12),\n",
    "        # distance_func=cosine_similarity,\n",
    "        alpha=0.01,\n",
    "    ),\n",
    "    num_particles=2048,\n",
    "    consensus=0.2,  # percentage\n",
    "    upper_thres=0.2,  # percentage\n",
    "    lower_thres=0.1,  # percentage\n",
    ")\n",
    "\n",
    "for i in range(1, blonde_video.shape[0]):\n",
    "    start_time = time.time()\n",
    "\n",
    "    frame = blonde_video[i, ...]\n",
    "\n",
    "    tracker.update(frame)\n",
    "\n",
    "    frame = visualize_particle_filter(\n",
    "        frame, tracker.particles, tracker.state, tracker.measure_model.template\n",
    "    )\n",
    "\n",
    "    delay = int(25 - (time.time() - start_time))\n",
    "    if cv2.waitKey(delay) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "    cv2.imshow(\"blonde\", frame[:, :, ::-1])  # Display the resulting frame\n",
    "    # ax.imshow(frame)\n",
    "    # display(fig)\n",
    "    # clear_output(wait=True)\n",
    "    # time.sleep(1)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_computer_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
