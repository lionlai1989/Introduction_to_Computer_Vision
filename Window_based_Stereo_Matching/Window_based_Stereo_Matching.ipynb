{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window-based Stereo Matching\n",
    "\n",
    "Stereo matching plays a pivotal role in 3D computer vision by computing the disparity\n",
    "map between a pair of stereo images. Nowadays, traditional methods, like the one\n",
    "presented in this notebook, have largely fallen out of favor in practical applications,\n",
    "primarily due to the emergence of superior neural network-based algorithms.\n",
    "\n",
    "Nevertheless, diving into the fundamentals of stereo matching offers a valuable\n",
    "opportunity to grasp the foundational aspects of this field and gain insights into\n",
    "potential pitfalls and challenges that persist in stereo matching algorithms. These\n",
    "challenges encompass issues such as occlusion, variations in image brightness, and image\n",
    "noise, which are prevalent in real-world scenarios. Familiarizing myself with these\n",
    "challenges serves as a building block for developing intuition on how to tackle them\n",
    "when working with more advanced neural network-based approaches. ðŸ˜Š\n",
    "\n",
    "**RULES:** As usual, **`OpenCV`** is banned in this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Stereo matching aims to determine the pixel disparity in the x-axis between two provided\n",
    "images: a left image and a right image. It assumes that the y-axes of these stereo\n",
    "images are perfectly aligned. However, in reality, this assumption often does not hold\n",
    "true, necessitating the rectification of stereo images. The accuracy of this\n",
    "rectification process hinges largely on the ability to locate feature points within both\n",
    "stereo images. For the purpose of this exercise, let's presume that we have stereo\n",
    "images perfectly aligned along the y-axis, enabling us to proceed with this tutorial.\n",
    "\n",
    "**Note:** In this notebook, all discussions and equations adhere to the conventions\n",
    "commonly used in computer vision for defining image coordinates. Accordingly, the x-axis\n",
    "extends towards the right, while the y-axis extends downward. However, when it comes to\n",
    "implementation, it's crucial to reverse the order of the parameters. This is because, in\n",
    "a numpy array, the first axis corresponds to the downward direction, while the second\n",
    "axis corresponds to the rightward direction.\n",
    "\n",
    "One approach within stereo matching involves framing the problem as an energy function\n",
    "minimization task. This energy function comprises two fundamental components: the data\n",
    "term and the smoothness term, which can be formally expressed as:\n",
    "\n",
    "$$\n",
    "E(D) = \\alpha E_{data}(D) + \\beta E_{smooth}(D)\n",
    "$$\n",
    "\n",
    "The data term, denoted as $E_{data}(D)$, can be informally described as follows:\n",
    "\n",
    "$$\n",
    "E_{data}(D) = \\sum_{(x,y)\\in{I}} C(x, y, D(x, y))\n",
    "$$\n",
    "\n",
    "Here, it quantifies the cost associated with the disparity values $D(x, y)$ for all\n",
    "pixel coordinates $(x, y)$ within the image $I$.\n",
    "\n",
    "The smoothness term, on the other hand, is defined as:\n",
    "\n",
    "$$\n",
    "E_{smooth}(D) = \\sum_{(p,q)\\in{\\epsilon}} V(d_p, d_q)\n",
    "$$\n",
    "\n",
    "This term captures the smoothness constraints by evaluating the relationship between\n",
    "disparities $d_p$â€‹ and $d_q$ for pixel pairs belonging to a defined neighborhood\n",
    "$\\epsilon$.\n",
    "\n",
    "In this context, $\\epsilon$ represents the set of neighboring pixels, and $V(d_p, d_q)$\n",
    "signifies the $L1$ distance between them. To illustrate, given a disparity value $d_p$\n",
    "for a pixel $p$ in the disparity map $D$, $d_q$ encompasses the collection of disparity\n",
    "values for all neighboring pixels surrounding $p$.\n",
    "\n",
    "For simplicity, we won't consider the smoothness term in this exercise. Thus, our energy\n",
    "function becomes $E(D) = E_{data}(D)$.\n",
    "\n",
    "It's important to note that we perform stereo matching in both the left-to-right and\n",
    "right-to-left directions. This is necessary due to variations in depth (discontinuities)\n",
    "and occlusions. In other words, some pixels that are visible in the left image may not\n",
    "be visible in the right image, and vice versa.\n",
    "\n",
    "To clarify, in the context of the stereo images provided below, the left image is\n",
    "captured from the perspective of the left viewpoint, while the right image is captured\n",
    "from the right viewpoint. You can observe that objects in the left image may appear to\n",
    "the right of their counterparts in the right image. This phenomenon arises from the\n",
    "inherent nature of stereo images.\n",
    "\n",
    "In line with the disparity map convention, the disparity value is computed by\n",
    "subtracting the x-coordinate of a pixel in the right image from the x-coordinate of the\n",
    "corresponding pixel in the left image, as shown in the equation:\n",
    "\n",
    "$$\n",
    "disparity = pixel_{left} - pixel_{right}\n",
    "$$\n",
    "\n",
    "For instance, if we aim to determine the disparity value for a pixel, such as the eyes\n",
    "of the statue, in the left image, the disparity value would be positive, indicating that\n",
    "this pixel is to the right of its corresponding point in the right image.\n",
    "\n",
    "It's important to note that if we reverse the order of the left and right images, the\n",
    "sign of the disparity will be inverted.\n",
    "\n",
    "<figure>\n",
    "  <div style=\"display: flex; justify-content: space-between;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "      <img src=\"./input/pair1-L.png\" style=\"width: 80%;\" alt=\"Left Image\">\n",
    "      <p><strong>Left Image</strong></p>\n",
    "      <p>The statue appears more to the right in the left image compared to its position in the right image.</p>\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "      <img src=\"./input/pair1-R.png\" style=\"width: 80%;\" alt=\"Right Image\">\n",
    "      <p><strong>Right Image</strong></p>\n",
    "      <p>The right image is captured from the right viewpoint.</p>\n",
    "    </div>\n",
    "  </div>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, feature, filters\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "import networkx\n",
    "from skimage import color\n",
    "import image_processing_utils\n",
    "\n",
    "\n",
    "gray_left = image_processing_utils.read_image(\"./input/pair0-L.png\")\n",
    "gray_right = image_processing_utils.read_image(\"./input/pair0-R.png\")\n",
    "statue_left = image_processing_utils.read_image(\"./input/pair1-L.png\")\n",
    "statue_right = image_processing_utils.read_image(\"./input/pair1-R.png\")\n",
    "statue_left_gt = image_processing_utils.read_image(\"./input/pair1-D_L.png\")\n",
    "statue_right_gt = image_processing_utils.read_image(\"./input/pair1-D_R.png\")\n",
    "cleaner_left = image_processing_utils.read_image(\"./input/pair2-L.png\")\n",
    "cleaner_right = image_processing_utils.read_image(\"./input/pair2-R.png\")\n",
    "cleaner_left_gt = image_processing_utils.read_image(\"./input/pair2-D_L.png\")\n",
    "cleaner_right_gt = image_processing_utils.read_image(\"./input/pair2-D_R.png\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gray_left.shape, gray_left.dtype)\n",
    "print(statue_left.shape, statue_left.dtype, statue_left_gt.shape, statue_left_gt.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum of Squared Difference and Sum of Absolute Difference\n",
    "\n",
    "Our primary objective is to find the disparity map $D$ that minimizes $E(D)$. In other\n",
    "words, we can define the cost for each pixel $(x, y)$ as follows:\n",
    "\n",
    "$$\n",
    "c(x, y, d) = \\sum_{i=-\\frac{W}{2}}^{\\frac{W}{2}} \\sum_{j=-\\frac{W}{2}}^{\\frac{W}{2}} [I_{left}(x+i, y+j) - I_{right}(x+i-d, y+j)]^2\n",
    "$$\n",
    "\n",
    "Here, $d$ spans a predefined range, and our aim is to find the best disparity value that\n",
    "minimizes the cost function, known as sum of squared differences (SSD), or\n",
    "alternatively, the sum of absolute differences (SAD). $W$ represents the width and\n",
    "height of the window. In this section, we'll compare SSD and SAD results to determine\n",
    "the superior approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd(left, right):\n",
    "    \"\"\"Sum of Squared Difference\"\"\"\n",
    "    assert left.shape == right.shape\n",
    "    return np.sum((left - right) ** 2)\n",
    "\n",
    "\n",
    "def sad(left, right):\n",
    "    \"\"\"Sum of Absolute Difference\"\"\"\n",
    "    assert left.shape == right.shape\n",
    "    return np.sum(np.absolute(left - right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_is_valid(x_min, x_max, y_min, y_max, width, height):\n",
    "    if x_min < 0 or y_min < 0:\n",
    "        # print(f\"x_min: {x_min}. y_min: {y_min}\")\n",
    "        return False\n",
    "    if x_max >= width or y_max >= height:\n",
    "        # print(f\"x_max: {x_max}. y_max: {y_max}\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def cal_disp_map(\n",
    "    left_img, right_img, window_size=3, disp_range=(-32, 32), cost_fun=None\n",
    "):\n",
    "    assert cost_fun is not None\n",
    "    assert left_img.shape == right_img.shape\n",
    "    # disparity could be positive or negative floating-point.\n",
    "    disparity_map = np.zeros_like(left_img, dtype=np.float64)\n",
    "\n",
    "    half_win = window_size // 2  # 3->1, 5->2\n",
    "    height, width = left_img.shape  # Get the image dimensions\n",
    "\n",
    "    # Loop through each pixel in the left image. Do not\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            min_cost = float(\"inf\")\n",
    "            best_disparity = None\n",
    "\n",
    "            # Define the search window coordinates\n",
    "            y_min, y_max = max(0, y - half_win), min(height - 1, y + half_win + 1)\n",
    "            x_min, x_max = max(0, x - half_win), min(width - 1, x + half_win + 1)\n",
    "            assert coord_is_valid(\n",
    "                x_min, x_max, y_min, y_max, width, height\n",
    "            ), f\"{x_min}, {x_max}, {y_min}, {y_max}, {width}, {height}\"\n",
    "\n",
    "            # Calculate the cost for each disparity value in the disparity range.\n",
    "            for disparity in range(disp_range[0], disp_range[1]):\n",
    "                # Apply disparty to the x axis of the right window.\n",
    "                if (\n",
    "                    coord_is_valid(\n",
    "                        x_min - disparity,\n",
    "                        x_max - disparity,\n",
    "                        y_min,\n",
    "                        y_max,\n",
    "                        width,\n",
    "                        height,\n",
    "                    )\n",
    "                    is False\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                # Extract the left and right image patches\n",
    "                left_patch = left_img[y_min : y_max + 1, x_min : x_max + 1]\n",
    "                right_patch = right_img[\n",
    "                    y_min : y_max + 1, x_min - disparity : x_max - disparity + 1\n",
    "                ]\n",
    "\n",
    "                cost = cost_fun(left_patch, right_patch)\n",
    "\n",
    "                # Update if we found a better disparity value\n",
    "                if cost < min_cost:\n",
    "                    min_cost = cost\n",
    "                    best_disparity = disparity\n",
    "\n",
    "            disparity_map[y, x] = best_disparity\n",
    "    return disparity_map\n",
    "\n",
    "\n",
    "image_data = [(ssd, \"SSD\"), (sad, \"SAD\")]\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(9, 4))\n",
    "\n",
    "for i, (cost_fun, title) in enumerate(image_data):\n",
    "    disp_map = cal_disp_map(\n",
    "        gray_left, gray_right, window_size=3, disp_range=(-5, 5), cost_fun=cost_fun\n",
    "    )\n",
    "\n",
    "    ax[i].set_title(f\"Left to right disparity map. {title}\")\n",
    "    im = ax[i].imshow(\n",
    "        disp_map,\n",
    "        cmap=\"plasma\",\n",
    "        aspect=\"auto\",\n",
    "        vmin=-5,\n",
    "        vmax=5,\n",
    "    )\n",
    "\n",
    "    cbar = fig.colorbar(im, ax=ax[i], orientation=\"vertical\")\n",
    "    cbar.set_label(\"Disparity Value\", rotation=270, labelpad=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**\n",
    "\"this plot shows that the right image needs to shift 5 pixels to the right to be aligned with left image.\"\n",
    "\n",
    "To be honest, the difference of SSD and SAD is not too much.\n",
    "the size of the disparity map is the same as left and right images'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_map = cal_disp_map(statue_left, statue_right, window_size=5, disp_range=(-10, 290), cost_fun=sad)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "ax.set_title(f\"Left to right disparity map. min:{np.min(disp_map)}. max:{np.max(disp_map)}\")\n",
    "im = ax.imshow(\n",
    "    disp_map,\n",
    "    cmap=\"plasma\",\n",
    "    aspect=\"auto\",\n",
    "    vmin=20,\n",
    "    vmax=200,\n",
    ")\n",
    "ax.set_axis_off()\n",
    "cbar = fig.colorbar(im, ax=ax, orientation=\"vertical\")\n",
    "cbar.set_label(\"Disparity Value\", rotation=270, labelpad=20)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Cross Correlation\n",
    "\n",
    "normalised cross-correlation (NCC)\n",
    "\n",
    "In the example of SSD and SAD, we essentially want to know the similarity of two 2D\n",
    "arrays. we can calculate the cosine similarity of these two 2D arrasy by using the eqaution:\n",
    "$$\n",
    "\\cos(\\theta) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\n",
    "\\cos(\\theta) = \\frac{\\sum_{i=1}^{n} (A_i \\cdot B_i)}{\\sqrt{\\sum_{i=1}^{n} A_i^2} \\cdot \\sqrt{\\sum_{i=1}^{n} B_i^2}}\n",
    "\n",
    "$$\n",
    "\n",
    "talk about normalized cross correlation a bit. given intuitive 2D example, with template\n",
    "matching. I want to emphasize that in the example, the disparity range is mostly\n",
    "negative, then why do i specify the range to include positive and negative range. it's\n",
    "because in reality, the stereo image are mostly from rectification. and the disparity in\n",
    "recitified images can be positive and negative. so it's a good habit to keep in mind\n",
    "that disparity could cover from negative to positive range.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncc(left, right):\n",
    "    \"\"\"Normalized Cross Correlation\"\"\"\n",
    "    assert left.shape == right.shape\n",
    "    return np.sum(left * right) / (\n",
    "        np.sqrt(np.sum(left**2)) * np.sqrt(np.sum(right**2))\n",
    "    )\n",
    "\n",
    "disp_map = cal_disp_map(statue_left, statue_right, window_size=5, disp_range=(0, 290), cost_fun=ncc)\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "ax.set_title(f\"Left to right disparity map. min:{np.min(disp_map)}. max:{np.max(disp_map)}\")\n",
    "im = ax.imshow(\n",
    "    disp_map,\n",
    "    cmap=\"plasma\",\n",
    "    aspect=\"auto\",\n",
    "    vmin=20,\n",
    "    vmax=200,\n",
    ")\n",
    "ax.set_axis_off()\n",
    "cbar = fig.colorbar(im, ax=ax, orientation=\"vertical\")\n",
    "cbar.set_label(\"Disparity Value\", rotation=270, labelpad=20)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_Introduction_to_Computer_Vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
