{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window-based Stereo Matching\n",
    "\n",
    "Stereo matching plays a pivotal role in 3D computer vision by computing the disparity\n",
    "map between a pair of stereo images. Nowadays, traditional methods, like the one\n",
    "presented in this notebook, have largely fallen out of favor in practical applications,\n",
    "primarily due to the emergence of superior neural network-based algorithms.\n",
    "\n",
    "Nevertheless, diving into the fundamentals of stereo matching offers a valuable\n",
    "opportunity to grasp the foundational aspects of this field and gain insights into\n",
    "potential pitfalls and challenges that persist in stereo matching algorithms. These\n",
    "challenges encompass issues such as occlusion, variations in image brightness, and image\n",
    "noise, which are prevalent in real-world scenarios. Familiarizing myself with these\n",
    "challenges serves as a building block for developing intuition on how to tackle them\n",
    "when working with more advanced neural network-based approaches. ðŸ˜Š\n",
    "\n",
    "**RULES:** As usual, **`OpenCV`** is banned in this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Stereo matching aims to determine pixel disparities along the x-axis between two\n",
    "provided images: a left image and a right image. It assumes that the y-axes of these\n",
    "stereo images are perfectly aligned. However, in reality, this assumption often doesn't\n",
    "hold true, necessitating stereo image rectification. The accuracy of this rectification\n",
    "process largely depends on locating feature points in both stereo images. For this\n",
    "exercise, we assume perfect y-axis alignment, allowing us to proceed with this tutorial.\n",
    "\n",
    "To clarify, in the context of the stereo images provided below, the left image is\n",
    "captured from the left viewpoint, and the right image is captured from the right\n",
    "viewpoint. Objects in the left image may appear to the right of their counterparts in\n",
    "the right image due to the inherent nature of stereo images.\n",
    "\n",
    "Following the disparity map convention, the disparity value is computed by subtracting\n",
    "the x-coordinate of a pixel in the right image from the x-coordinate of the\n",
    "corresponding pixel in the left image, as shown in the equation:\n",
    "\n",
    "$$\n",
    "\\text{disparity} = \\text{pixel}_{\\text{left}} - pixel_{\\text{right}}\n",
    "$$\n",
    "\n",
    "For instance, if we aim to determine the disparity value for a pixel, such as the eyes\n",
    "of the statue, in the left image, the disparity value would be positive, indicating that\n",
    "this pixel is to the right of its corresponding point in the right image.\n",
    "\n",
    "It's important to note that if we reverse the order of the left and right images, the\n",
    "sign of the disparity will be inverted.\n",
    "\n",
    "<figure>\n",
    "  <div style=\"display: flex; justify-content: space-between;\">\n",
    "    <div style=\"text-align: center;\">\n",
    "      <img src=\"./input/pair1-L.png\" style=\"width: 80%;\" alt=\"Left Image\">\n",
    "      <p><strong>Left Image</strong></p>\n",
    "      <p>The statue appears more to the right in the left image compared to its position in the right image.</p>\n",
    "    </div>\n",
    "    <div style=\"text-align: center;\">\n",
    "      <img src=\"./input/pair1-R.png\" style=\"width: 80%;\" alt=\"Right Image\">\n",
    "      <p><strong>Right Image</strong></p>\n",
    "      <p>The right image is captured from the right viewpoint.</p>\n",
    "    </div>\n",
    "  </div>\n",
    "</figure>\n",
    "\n",
    "**Note:** In this notebook, all discussions and equations follow the conventions\n",
    "commonly used in computer vision for defining image coordinates. The x-axis extends\n",
    "towards the right, and the y-axis extends downward. However, for implementation, it's\n",
    "crucial to reverse the order of the parameters. This is because, in a numpy array, the\n",
    "first axis corresponds to the downward direction, while the second axis corresponds to\n",
    "the rightward direction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import image_processing_utils\n",
    "\n",
    "# 0-1\n",
    "gray_left = image_processing_utils.read_image(\"./input/pair0-L.png\")\n",
    "gray_right = image_processing_utils.read_image(\"./input/pair0-R.png\")\n",
    "statue_left = image_processing_utils.read_image(\"./input/pair1-L.png\")\n",
    "statue_right = image_processing_utils.read_image(\"./input/pair1-R.png\")\n",
    "cleaner_left = image_processing_utils.read_image(\"./input/pair2-L.png\")\n",
    "cleaner_right = image_processing_utils.read_image(\"./input/pair2-R.png\")\n",
    "# 0-255\n",
    "statue_left_gt = io.imread(\"./input/pair1-D_L.png\")\n",
    "statue_right_gt = io.imread(\"./input/pair1-D_R.png\")\n",
    "cleaner_left_gt = io.imread(\"./input/pair2-D_L.png\")\n",
    "cleaner_right_gt = io.imread(\"./input/pair2-D_R.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Energy Minimization\n",
    "\n",
    "One of the approaches within stereo matching involves framing the problem as an energy\n",
    "function minimization task. This energy function comprises two fundamental components:\n",
    "the data term and the smoothness term, which can be formally expressed as:\n",
    "\n",
    "$$\n",
    "E(D) = \\alpha E_{data}(D) + \\beta E_{smooth}(D)\n",
    "$$\n",
    "\n",
    "The data term, denoted as $E_{data}(D)$, can be informally described as follows:\n",
    "\n",
    "$$\n",
    "E_{data}(D) = \\sum_{(x,y)\\in{I}} C(x, y, D(x, y))\n",
    "$$\n",
    "\n",
    "Here, it quantifies the cost associated with the disparity values $D(x, y)$ for all\n",
    "pixel coordinates $(x, y)$ within the image $I$.\n",
    "\n",
    "The smoothness term, on the other hand, is defined as:\n",
    "\n",
    "$$\n",
    "E_{smooth}(D) = \\sum_{(p,q)\\in{\\epsilon}} V(d_p, d_q)\n",
    "$$\n",
    "\n",
    "This term captures smoothness constraints by evaluating the relationship between\n",
    "disparities $d_p$ and $d_q$ for pixel pairs belonging to a defined neighborhood\n",
    "$\\epsilon$. In this context, $\\epsilon$ represents the set of neighboring pixels, and\n",
    "$V(d_p, d_q)$ signifies the $L1$ distance between them. To illustrate, given a disparity\n",
    "value $d_p$ for a pixel $p$ in the disparity map $D$, $d_q$ encompasses the collection\n",
    "of disparity values for all neighboring pixels surrounding $p.\n",
    "\n",
    "It's important to note that we perform stereo matching in both the left-to-right and\n",
    "right-to-left directions. This is necessary due to variations in depth (discontinuities)\n",
    "and occlusions. In other words, some pixels that are visible in the left image may not\n",
    "be visible in the right image, and vice versa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_disp_map(\n",
    "    left_img, right_img, window_size=3, disp_range=(-32, 32), cost_fun=None\n",
    "):\n",
    "    assert cost_fun is not None\n",
    "    assert left_img.shape == right_img.shape\n",
    "    # disparity could be positive or negative floating-point.\n",
    "    disparity_map = np.zeros_like(left_img, dtype=np.float64)\n",
    "\n",
    "    half_win = window_size // 2  # 3->1, 5->2\n",
    "    height, width = left_img.shape  # Get the image dimensions\n",
    "\n",
    "    # Loop through each pixel in the left image. Do not\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            min_cost = float(\"inf\")\n",
    "            best_disparity = None\n",
    "\n",
    "            # Define the search window coordinates\n",
    "            y_min, y_max = max(0, y - half_win), min(height - 1, y + half_win + 1)\n",
    "            x_min, x_max = max(0, x - half_win), min(width - 1, x + half_win + 1)\n",
    "            assert image_processing_utils.coord_is_valid(\n",
    "                x_min, x_max, y_min, y_max, width, height\n",
    "            ), f\"{x_min}, {x_max}, {y_min}, {y_max}, {width}, {height}\"\n",
    "\n",
    "            left_patches = []\n",
    "            right_patches = []\n",
    "            disp_candidates = []\n",
    "            # Calculate the cost for each disparity value in the disparity range.\n",
    "            for disp in range(disp_range[0], disp_range[1]):\n",
    "                # Apply disparty to the x axis of the right window.\n",
    "                if (\n",
    "                    image_processing_utils.coord_is_valid(\n",
    "                        x_min - disp,\n",
    "                        x_max - disp,\n",
    "                        y_min,\n",
    "                        y_max,\n",
    "                        width,\n",
    "                        height,\n",
    "                    )\n",
    "                    is False\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                # Extract the left and right image patches\n",
    "                left_patch = left_img[y_min : y_max + 1, x_min : x_max + 1]\n",
    "                right_patch = right_img[\n",
    "                    y_min : y_max + 1, x_min - disp : x_max - disp + 1\n",
    "                ]\n",
    "                left_patches.append(left_patch)\n",
    "                right_patches.append(right_patch)\n",
    "                disp_candidates.append(disp)\n",
    "\n",
    "            costs = cost_fun(\n",
    "                np.stack(left_patches, axis=0), np.stack(right_patches, axis=0)\n",
    "            )\n",
    "            assert np.any(np.isnan(costs)) == False\n",
    "            assert costs.size == len(disp_candidates)\n",
    "            disparity_map[y, x] = disp_candidates[np.argmin(costs)]\n",
    "\n",
    "    return disparity_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum of Squared/Absolute Difference and Cosine Similarity\n",
    "\n",
    "Our primary goal is to find the disparity map $D$ that minimizes $E(D)$. To achieve\n",
    "this, we define the cost function for each pixel $(x, y)$ as follows:\n",
    "\n",
    "$$\n",
    "c(x, y, d) = \\sum_{i=-\\frac{W}{2}}^{\\frac{W}{2}} \\sum_{j=-\\frac{W}{2}}^{\\frac{W}{2}}\n",
    "\\text{Diff}(I_{\\text{left}}(x+i, y+j), I_{\\text{right}}(x+i-d, y+j))\n",
    "$$\n",
    "\n",
    "Here, $d$ spans a predefined range and $W$ represents the width and height of the target\n",
    "window. Our aim is to find the optimal disparity value that minimizes the cost\n",
    "$c(x, y, d)$ for the pixel $(x, y)$.\n",
    "\n",
    "The $\\text{Diff}(a, b)$ function quantifies the dissimilarity between two vectors $a$\n",
    "and $b$. We employ three methods to assess the magnitude of differences between two\n",
    "multi-dimensional vectors. These methods are as follows:\n",
    "\n",
    "**Sum of Squared Differences (SSD):**\n",
    "\n",
    "$$\n",
    "[I_{left}(x+i, y+j) - I_{right}(x+i-d, y+j)]^2\n",
    "$$\n",
    "\n",
    "**Sum of Absolute Differences (SAD):**\n",
    "\n",
    "$$\n",
    "|I_{left}(x+i, y+j) - I_{right}(x+i-d, y+j)|\n",
    "$$\n",
    "\n",
    "**Cosine Similarity:**\n",
    "\n",
    "$$\n",
    "\\cos(\\theta) = \\frac{\\bm{A} \\cdot \\bm{B}}{\\|\\bm{A}\\| \\|\\bm{B}\\|} = \\frac{\\sum_{i=1}^{n} (A_i \\cdot B_i)}{\\sqrt{\\sum_{i=1}^{n} A_i^2} \\cdot \\sqrt{\\sum_{i=1}^{n} B_i^2}}\n",
    "$$\n",
    "\n",
    "Conventionally, SSD and SAD are two functions that measure the dissimilarity of two\n",
    "vectors, with _a smaller cost indicating a better match_. However, in the case of cosine\n",
    "similarity, _a larger value indicates that two vectors are more similar_. Therefore, we\n",
    "need to inverse the sign in the implementation.\n",
    "\n",
    "We are now prepared to implement SSD, SAD, and cosine similarity functions. To validate\n",
    "our implementations, we will employ a toy example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssd(left, right):\n",
    "    \"\"\"Sum of Squared Difference\n",
    "    left, right: C x H x W\"\"\"\n",
    "    assert left.shape == right.shape and left.ndim == 3\n",
    "    return np.sum((left - right) ** 2, axis=(1, 2))\n",
    "\n",
    "\n",
    "def sad(left, right):\n",
    "    \"\"\"Sum of Absolute Difference\n",
    "    left, right: C x H x W\"\"\"\n",
    "    assert left.shape == right.shape and left.ndim == 3\n",
    "    return np.sum(np.absolute(left - right), axis=(1, 2))\n",
    "\n",
    "\n",
    "def cosine_similarity(left, right):\n",
    "    \"\"\"Cosine Similarity\n",
    "    left, right: C x H x W\"\"\"\n",
    "    assert left.shape == right.shape and left.ndim == 3\n",
    "    dividend = np.sum(np.multiply(left, right), axis=(1, 2))\n",
    "    assert dividend.shape[0] == left.shape[0]\n",
    "    divisor = np.multiply(\n",
    "        np.sqrt(np.sum(left**2, axis=(1, 2))),\n",
    "        np.sqrt(np.sum(right**2, axis=(1, 2))),\n",
    "    )\n",
    "    assert divisor.shape[0] == left.shape[0]\n",
    "    assert np.all(divisor != 0), f\"divisor has 0 in it. {divisor}\"\n",
    "    return -1 * np.divide(dividend, divisor)\n",
    "\n",
    "\n",
    "image_data = [(ssd, \"SSD\"), (sad, \"SAD\"), (cosine_similarity, \"Cosine Similarity\")]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(15, 3))\n",
    "fig.suptitle(\"Toy stereo images and left-to-right disparity map.\")\n",
    "ax[0].set_title(\"Left image\")\n",
    "ax[0].imshow(gray_left, cmap=\"gray\", aspect=\"equal\")\n",
    "ax[1].set_title(\"Right image\")\n",
    "ax[1].imshow(gray_right, cmap=\"gray\", aspect=\"equal\")\n",
    "\n",
    "for i, (cost_fun, title) in enumerate(image_data):\n",
    "    disp_map = cal_disp_map(\n",
    "        gray_left, gray_right, window_size=3, disp_range=(-5, 5), cost_fun=cost_fun\n",
    "    )\n",
    "\n",
    "    ax[i + 2].set_title(f\"{title}\")\n",
    "    im = ax[i + 2].imshow(disp_map, cmap=\"RdYlGn\", aspect=\"equal\", vmin=-5, vmax=5)\n",
    "\n",
    "    cbar = fig.colorbar(im, ax=ax[i + 2], orientation=\"vertical\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**\n",
    "\n",
    "In our toy example, the black square in the left image is approximately two pixels to\n",
    "the right of the corresponding square in the right image. Consequently, we anticipate\n",
    "disparity values of approximately two in the left-to-right disparity map. Additionally,\n",
    "it's essential to note that both stereo images must _have the same size_, and the output\n",
    "disparity map will _match the size of the input images_.\n",
    "\n",
    "With this pipeline validated, we are ready to apply it to more realistic stereo images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Optimal Disparity Search Range\n",
    "\n",
    "Before applying our stereo matching pipeline to \"realistic\" images, it's crucial to\n",
    "address how we define the search range for the disparity map, encompassing both the\n",
    "minimum and maximum disparities. In our toy example and \"realistic\" images with known\n",
    "ground truth disparity maps, determining the optimal range is straightforward. However,\n",
    "in real-world scenarios, obtaining this information is challenging due to unpredictable\n",
    "object sizes and varying distances from the camera. For instance, in a self-driving\n",
    "car's context, cars and pedestrians can have varying distances, leading to diverse\n",
    "disparity values.\n",
    "\n",
    "To tackle this challenge, one approach is to employ feature matching algorithms like\n",
    "**SIFT** to locate and match feature points in stereo images. Once we identify matching\n",
    "feature points in the left and right images, we can estimate the initial disparity range\n",
    "by measuring the x-axis distance between these points (possibly with some margins). As\n",
    "the number of paired feature points in the stereo image increases, these points tend to\n",
    "scatter across the four corners of the image, providing a more accurate estimate of the\n",
    "disparity search range.\n",
    "\n",
    "Moreover, it's important to note that the search range for disparity values can\n",
    "encompass both **negative** and **positive** values. In 3D computer vision, stereo\n",
    "images are typically rectified using the fundamental matrix. As a result, disparity\n",
    "values can vary across the entire range, including both negative and positive values,\n",
    "rather than being limited to exclusively negative or positive values. This flexibility\n",
    "is essential to accurately represent disparities in the real world.\n",
    "\n",
    "However, for the purposes of this tutorial, we will simplify the process by using the\n",
    "disparity values from the ground truth image to set `disp_min` and `disp_max`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_min = 0\n",
    "disp_max = 150\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = [\n",
    "    (ssd, \"SSD\", \"equal\"),\n",
    "    (sad, \"SAD\", \"equal\"),\n",
    "    (cosine_similarity, \"Cosine Similarity\", \"equal\"),\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(18, 4))\n",
    "fig.suptitle(\"Ground Truth and Left-to-right disparity map.\")\n",
    "\n",
    "ax[0].set_title(\n",
    "    f\"Ground Truth. Min:{np.min(statue_left_gt)}. Max:{np.max(statue_left_gt)}\"\n",
    ")\n",
    "ax[0].imshow(statue_left_gt / 2, cmap=\"RdYlGn\", aspect=\"auto\", vmin=0, vmax=150)\n",
    "ax[0].set_axis_off()\n",
    "\n",
    "\n",
    "for i, (cost_fun, title, aspect) in enumerate(image_data):\n",
    "    disp_map = cal_disp_map(\n",
    "        statue_left,\n",
    "        statue_right,\n",
    "        window_size=5,\n",
    "        disp_range=(disp_min, disp_max),\n",
    "        cost_fun=cost_fun,\n",
    "    )\n",
    "    ax[i + 1].set_title(f\"{title}. Min:{np.min(disp_map)}. Max:{np.max(disp_map)}\")\n",
    "    im = ax[i + 1].imshow(disp_map, cmap=\"RdYlGn\", aspect=aspect, vmin=0, vmax=150)\n",
    "    ax[i + 1].set_axis_off()\n",
    "\n",
    "cbar = fig.colorbar(im, ax=ax[0], orientation=\"vertical\")\n",
    "cbar.set_label(\"Disparity Value\", rotation=270, labelpad=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**\n",
    "\n",
    "-   SSD and SAD produce nearly identical results, with cosine similarity slightly\n",
    "    outperforming them. This improvement can be attributed to cosine similarity's\n",
    "    ability to assess vector direction rather than merely focusing on magnitude\n",
    "    differences. Therefore, we will exclusively compare SSD and cosine similarity in the\n",
    "    ongoing experiments.\n",
    "\n",
    "-   Occlusion: On the left edges of the image, we observe extremely small disparity\n",
    "    values, which are unrealistic and indicative of occlusion. Ideally, occluded pixels\n",
    "    should undergo separate processing to clearly identify which pixels should be\n",
    "    excluded from application due to occlusion.\n",
    "\n",
    "-   Incorrect Disparity in Ground Truth: An unusual observation regarding the ground\n",
    "    truth image is that its values are inaccurate. Upon manual measurement using an\n",
    "    image viewer, the measured disparity between stereo images is only half the value\n",
    "    indicated in the ground truth image.\n",
    "\n",
    "Next, we will apply the same pipeline to aother realistic image, as demonstrated below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = [\n",
    "    (ssd, \"SSD\", \"equal\"),\n",
    "    (sad, \"SAD\", \"equal\"),\n",
    "    (cosine_similarity, \"Cosine Similarity\", \"equal\"),\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(18, 4))\n",
    "fig.suptitle(\"Ground Truth and Left-to-right disparity map.\")\n",
    "\n",
    "ax[0].set_title(\n",
    "    f\"Ground Truth. Min:{np.min(cleaner_left_gt)}. Max:{np.max(cleaner_left_gt)}\"\n",
    ")\n",
    "ax[0].imshow(cleaner_left_gt / 2, cmap=\"RdYlGn\", aspect=\"auto\", vmin=0, vmax=150)\n",
    "ax[0].set_axis_off()\n",
    "\n",
    "\n",
    "for i, (cost_fun, title, aspect) in enumerate(image_data):\n",
    "    disp_map = cal_disp_map(\n",
    "        cleaner_left,\n",
    "        cleaner_right,\n",
    "        window_size=5,\n",
    "        disp_range=(disp_min, disp_max),\n",
    "        cost_fun=cost_fun,\n",
    "    )\n",
    "    ax[i + 1].set_title(f\"{title}. Min:{np.min(disp_map)}. Max:{np.max(disp_map)}\")\n",
    "    im = ax[i + 1].imshow(disp_map, cmap=\"RdYlGn\", aspect=aspect, vmin=0, vmax=150)\n",
    "    ax[i + 1].set_axis_off()\n",
    "\n",
    "cbar = fig.colorbar(im, ax=ax[0], orientation=\"vertical\")\n",
    "cbar.set_label(\"Disparity Value\", rotation=270, labelpad=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Noise and Brightness Variation\n",
    "\n",
    "We are now prepared to investigate how SSD and cosine similarity perform when faced with\n",
    "stereo images subjected to noise and brightness variation. Specifically, the following\n",
    "modifications have been made to the left image, while the right image remains unaltered:\n",
    "\n",
    "-   **Gaussian Noise Addition:** Gaussian noise with a mean of `0.0` and a standard\n",
    "    deviation of `0.05` has been introduced to the left image.\n",
    "\n",
    "-   **Brightness Enhancement:** The brightness of the left image has been gradually\n",
    "    increased by `30%` from left to right. In other words, if the left image pixel values\n",
    "    range from 0 to 1, we have added a range, `0` to `0.3`, to each pixel's value.\n",
    "\n",
    "We will now examine the impact of these adjustments as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(image, noise_mean=0, noise_std=0.05):\n",
    "    # Generate random white noise.\n",
    "    noise = np.random.normal(loc=noise_mean, scale=noise_std, size=image.shape)\n",
    "\n",
    "    noisy_image = np.clip(image + noise, 0, 1)\n",
    "    return noisy_image\n",
    "\n",
    "\n",
    "def brightness(shape, minmax=(0, 0.1)):\n",
    "    height = shape[0]\n",
    "    width = shape[1]\n",
    "    mid = (minmax[0] + minmax[1]) / 2\n",
    "    ret = np.zeros((height, width)) - mid\n",
    "    step = (minmax[1] - minmax[0]) / width\n",
    "    for i in range(width):\n",
    "        ret[:, i] = step * i\n",
    "    return ret\n",
    "\n",
    "\n",
    "def vary_brightness(image, ratio=0.1):\n",
    "    image_min = np.min(image)\n",
    "    image_max = np.max(image)\n",
    "    image_range = image_max - image_min\n",
    "\n",
    "    brightness_variation = image_range * ratio\n",
    "    tmp = brightness(image.shape, minmax=(0, brightness_variation))\n",
    "    adjusted_image = np.clip(image + tmp, 0, 1)\n",
    "    return adjusted_image\n",
    "\n",
    "\n",
    "image_data = [(statue_left, \"Statue image\"), (cleaner_left, \"Cleaner image\")]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(13, 7))\n",
    "ax[0, 0].set_title(f\"Original image\")\n",
    "ax[0, 1].set_title(\"Gaussian noise\")\n",
    "ax[0, 2].set_title(\"Brightness variation\")\n",
    "for i, (image, title) in enumerate(image_data):\n",
    "    noise_image = add_noise(image, noise_mean=0, noise_std=0.05)\n",
    "    bright_image = vary_brightness(image, ratio=0.3)\n",
    "    ax[i, 0].imshow(image, cmap=\"gray\", aspect=\"equal\")\n",
    "    ax[i, 0].set_axis_off()\n",
    "    ax[i, 1].imshow(noise_image, cmap=\"gray\", aspect=\"equal\")\n",
    "    ax[i, 1].set_axis_off()\n",
    "    ax[i, 2].imshow(bright_image, cmap=\"gray\", aspect=\"equal\")\n",
    "    ax[i, 2].set_axis_off()\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_statue_left = add_noise(statue_left, noise_mean=0, noise_std=0.05)\n",
    "bright_statue_left = vary_brightness(statue_left, ratio=0.3)\n",
    "image_data = [\n",
    "    (ssd, noise_statue_left, \"Gaussian noise. SSD.\"),\n",
    "    (ssd, bright_statue_left, \"Brightness variation. SSD.\"),\n",
    "    (cosine_similarity, noise_statue_left, \"Gaussian noise. Cosine similarity.\"),\n",
    "    (cosine_similarity, bright_statue_left, \"Brightness variation. Cosine similarity.\"),\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(20, 4))\n",
    "fig.suptitle(\n",
    "    \"Ground Truth and disparity maps with Gaussian noise and brightness variation.\"\n",
    ")\n",
    "\n",
    "ax[0].set_title(f\"Ground Truth.\")\n",
    "ax[0].imshow(statue_left_gt / 2, cmap=\"RdYlGn\", aspect=\"auto\", vmin=0, vmax=150)\n",
    "ax[0].set_axis_off()\n",
    "\n",
    "for i, (cost_fun, img, title) in enumerate(image_data):\n",
    "    disp_map = cal_disp_map(\n",
    "        img,\n",
    "        statue_right,\n",
    "        window_size=5,\n",
    "        disp_range=(disp_min, disp_max),\n",
    "        cost_fun=cost_fun,\n",
    "    )\n",
    "    ax[i + 1].set_title(f\"{title}\")\n",
    "    ax[i + 1].imshow(disp_map, cmap=\"RdYlGn\", aspect=\"equal\", vmin=0, vmax=150)\n",
    "    ax[i + 1].set_axis_off()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_cleaner_left = add_noise(cleaner_left, noise_mean=0, noise_std=0.05)\n",
    "bright_cleaner_left = vary_brightness(cleaner_left, ratio=0.3)\n",
    "image_data = [\n",
    "    (ssd, noise_cleaner_left, \"Gaussian noise. SSD.\"),\n",
    "    (ssd, bright_cleaner_left, \"Brightness variation. SSD.\"),\n",
    "    (cosine_similarity, noise_cleaner_left, \"Gaussian noise. Cosine similarity.\"),\n",
    "    (\n",
    "        cosine_similarity,\n",
    "        bright_cleaner_left,\n",
    "        \"Brightness variation. Cosine similarity.\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(20, 4))\n",
    "fig.suptitle(\n",
    "    \"Ground Truth and disparity maps with Gaussian noise and brightness variation.\"\n",
    ")\n",
    "\n",
    "ax[0].set_title(f\"Ground Truth.\")\n",
    "ax[0].imshow(statue_left_gt / 2, cmap=\"RdYlGn\", aspect=\"auto\", vmin=0, vmax=150)\n",
    "ax[0].set_axis_off()\n",
    "\n",
    "for i, (cost_fun, img, title) in enumerate(image_data):\n",
    "    disp_map = cal_disp_map(\n",
    "        img,\n",
    "        cleaner_right,\n",
    "        window_size=5,\n",
    "        disp_range=(disp_min, disp_max),\n",
    "        cost_fun=cost_fun,\n",
    "    )\n",
    "    ax[i + 1].set_title(f\"{title}\")\n",
    "    ax[i + 1].imshow(disp_map, cmap=\"RdYlGn\", aspect=\"equal\", vmin=0, vmax=150)\n",
    "    ax[i + 1].set_axis_off()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In my humble opinion, window-based stereo matching appears to be one of the most\n",
    "straightforward and accessible algorithms among various stereo matching methods.\n",
    "Throughout this tutorial, we've gained insights into implementing window-based stereo\n",
    "matching using three different techniques. Additionally, we've witnessed how these\n",
    "methods exhibit varying performance when subjected to external factors affecting image\n",
    "quality, such as noise and brightness variation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Be Discussed\n",
    "\n",
    "Normalized Cross Correlation, Occulsion, filter disparity with large costs greater than threshold.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_Introduction_to_Computer_Vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
