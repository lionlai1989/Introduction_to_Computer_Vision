{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images as Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In computer vision, images are more than mere pixels with colors; they are representations of a function $f(x, y)$. Here, 'x' signifies the horizontal rightward direction, 'y' denotes the vertical downward direction, and $f(x, y)$ corresponds to the pixel value, typically in grayscale or RGB, for a given pixel coordinate pair. This convention will be consistently followed throughout this repository unless otherwise specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import color, io\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are two example images opened using `Pillow` and visualized using `matplotlib`. Notably, the horizontal axis (x-axis) extends from left to right, while the vertical axis (y-axis) extends from top to bottom. Consequently, it's important to note that the image's origin is at the **top-leftmost point**, which might appear counterintuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_path = \"./input/ps0-1-a-1.tiff\"\n",
    "img2_path = \"./input/ps0-1-a-2.tiff\"\n",
    "\n",
    "# gray-image: MxN\n",
    "# RGB-image: MxNx3\n",
    "# RGBA-image: MxNx4\n",
    "arr1 = io.imread(img1_path)\n",
    "\n",
    "with Image.open(img2_path) as pil_im2:\n",
    "    arr2 = np.asarray(pil_im2)\n",
    "    # arr2 = np.asarray(pil_im2.convert('L')) RGB -> GRAY. Notice the grayscale range is 0~255 with this function.\n",
    "\n",
    "\n",
    "print(f\"The left (car) image {img1_path} has shape {arr1.shape} and its order is RGB.\") # HxWx3, RGB\n",
    "print(f\"The right (boat) image {img2_path} has shape {arr2.shape} and its order is {pil_im2.mode}.\") # HxWx3, RGB\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(6, 4)) # figsize(Width, height) in inches.\n",
    "\n",
    "ax[0].imshow(arr1)\n",
    "ax[1].imshow(arr2)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# with Image.open(img2_path) as pil_im2:\n",
    "#     arr2 = np.asarray(pil_im2.convert('L')) # RGB -> GRAY\n",
    "#     h2, w2 = arr2.shape\n",
    "#     center2 = (int(h2/2), (w2/2)) # y, x\n",
    "#     # arr2 is an immutable array. If written, the error below is shown:\n",
    "#     # ValueError: assignment destination is read-only\n",
    "#     output = np.zeros_like(arr2)\n",
    "#     output[:, :] = arr2[:, :]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Channels\n",
    "\n",
    "Now, let's explore the images further to gain a deeper understanding of what a digital image really is by doing the following:\n",
    "\n",
    "- Plot monochrome image by converting RGB to grayscale image.\n",
    "- Plot monochrome image by selecting R channel.\n",
    "- Plot monochrome image by selecting G channel.\n",
    "- Plot monochrome image by selecting B channel.\n",
    "- Swap the red (R) and blue (B) channels.\n",
    "- Swap the red (G) and blue (B) channels.\n",
    "\n",
    "Notice that the pixel range for `RGB to Gray` image is `0` to `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Image.open(img1_path) as im:\n",
    "    arr = np.asarray(im)\n",
    "\n",
    "fontsize = 12\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    nrows=2, ncols=3, figsize=(9, 6)\n",
    ")  # figsize(Width, height) in inches.\n",
    "\n",
    "ax[0, 0].imshow(color.rgb2gray(arr), cmap=\"gray\", vmin=0, vmax=1)\n",
    "ax[0, 0].set_title(\"RGB to Gray\", fontsize=fontsize)\n",
    "ax[0, 0].axis('off')  # Remove scale axis\n",
    "\n",
    "ax[0, 1].imshow(arr[:, :, 0], cmap=\"gray\", vmin=0, vmax=255)  # R channel\n",
    "ax[0, 1].set_title(\"Red\", fontsize=fontsize)\n",
    "ax[0, 1].axis('off')\n",
    "\n",
    "ax[1, 0].imshow(arr[:, :, 1], cmap=\"gray\", vmin=0, vmax=255)  # G channel\n",
    "ax[1, 0].set_title(\"Green\", fontsize=fontsize)\n",
    "ax[1, 0].axis('off')\n",
    "\n",
    "ax[1, 1].imshow(arr[:, :, 2], cmap=\"gray\", vmin=0, vmax=255)  # B channel\n",
    "ax[1, 1].set_title(\"Blue\", fontsize=fontsize)\n",
    "ax[1, 1].axis('off')\n",
    "\n",
    "# img[:,:,::-1] will create a view with swapped channels, `img` will stay unchanged.\n",
    "ax[0, 2].imshow(arr[:, :, ::-1]) # Swap the red and blue channel. Or `[:, :, [2, 1, 0]]`\n",
    "ax[0, 2].set_title(\"Swap R and B\", fontsize=fontsize)\n",
    "ax[0, 2].axis('off')\n",
    "\n",
    "ax[1, 2].imshow(arr[:, :, [0, 2, 1]])  # Swap the green and blue channel\n",
    "ax[1, 2].set_title(\"Swap G and B\", fontsize=fontsize)\n",
    "ax[1, 2].axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "Let's analyze the R, G, and B monochrome images separately. The \"green\" image appears brighter due to the outdoor scene with trees and grass. Conversely, in the \"red\" image, the car appears dark primarily because it is blue, resulting in its darkness in the \"red\" image and brightness in the \"blue\" image. Additionally, trees and grass appear darker in both the \"green\" and \"red\" images due to the absorption of more high-frequency light, particularly blue light, by natural green objects.\n",
    "\n",
    "In summary, computer vision algorithms perform better when images capture more information or details. Consequently, these algorithms excel with natural objects in outdoor scenes and also perform well with artificial objects under indoor lighting conditions. However, it's important to note that RGB and RGB-derived grayscale images cover a wide spectrum of light, making them versatile for various scenarios."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Radiometric Operation: Calculate Mean and Standard Deviation\n",
    "\n",
    "Let's compute the mean and standard deviation (STD) for two images. The mean provides insight into the average brightness of an image, while STD indicates the degree of brightness variation.\n",
    "\n",
    "* Begin by determining the minimum and maximum pixel values of the boat image. Calculate the mean and standard deviation as well. It's essential to describe the methodology employed for these computations.\n",
    "\n",
    "* Next, perform the following operations on all pixels:\n",
    "  - Subtract the mean value.\n",
    "  - Divide the result by the standard deviation.\n",
    "  - Adjust the scaling factor: multiply by 10 if the image intensity ranges from 0 to 255, or by 0.05 if the range is from 0.0 to 1.0.\n",
    "  - Finally, add the mean value back to the adjusted pixel values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = io.imread(img2_path)\n",
    "\n",
    "green = arr[:, :, 1]\n",
    "minimum = np.min(green)\n",
    "maximum = np.max(green)\n",
    "mean = np.mean(green)\n",
    "std = np.std(green)\n",
    "print(f\"Characteristic of the green channel of the boat image: \\nMin: {minimum}. Max: {maximum}. Mean: {mean}. Std: {std}.\")\n",
    "\n",
    "normal = (mean+10*(green-mean)/std)\n",
    "normal = normal.astype(np.uint8)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(6, 3))\n",
    "\n",
    "ax[0].imshow(green, cmap=\"gray\", vmin=0, vmax=255)\n",
    "ax[0].set_title(\"Original Green\", fontsize=fontsize)\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(normal, cmap=\"gray\", vmin=0, vmax=255)\n",
    "ax[1].set_title(\"Standarized Green\", fontsize=fontsize)\n",
    "ax[1].axis('off')\n",
    "\n",
    "# Save the 'green' and 'normal' image.\n",
    "plt.imsave(\"./images/green_channel_original.png\", green, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.imsave(\"./images/green_channel_standardized.png\", normal, cmap=\"gray\", vmin=0, vmax=255)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "The green channel exhibits a mean pixel value of 124.3 and a standard deviation (STD) of 77, indicating a well-exposed image with balanced brightness, neither too bright nor too dark. The visual appearance on the screen is pleasing. However, post-standardization of the green channel, the resulting image appears predominantly gray. This occurs because standardization shifts the entire image toward the midpoint of the pixel range, which, in the case of an 8-bit image ranging from 0 to 255, corresponds to gray. Thus, the overall gray appearance is a consequence of this adjustment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric Operation: Shifting the Image\n",
    "\n",
    "In this section, we apply a geometric operation to the image to observe its resulting appearance.\n",
    "\n",
    "* Perform a leftward shift of 1 pixel on the green channel.\n",
    "\n",
    "* Subtract the original green channel with the shifted green channel, ensuring that pixel values remain within the valid range (what do negative numbers for pixels mean anyway?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = io.imread(img1_path)\n",
    "\n",
    "green = arr[:, :, 1]\n",
    "\n",
    "shift_pixel = 1\n",
    "\n",
    "shifted = np.zeros_like(green)\n",
    "shifted[:, :-shift_pixel] = green[:, shift_pixel:]\n",
    "\n",
    "sub_shift_green = green-shifted\n",
    "sub_shift_green[sub_shift_green<0] = 0\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(6, 3))\n",
    "\n",
    "ax[0].imshow(green, cmap=\"gray\", vmin=0, vmax=255)\n",
    "ax[0].set_title(\"Original green\", fontsize=fontsize)\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(sub_shift_green, cmap=\"gray\", vmin=0, vmax=255)\n",
    "ax[1].set_title(\"Subtract original with shifted green\", fontsize=fontsize)\n",
    "ax[1].axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise\n",
    "\n",
    "To assess the impact of noise on the original colored image, Gaussian noise is incrementally added to the green and blue channels separately. The sigma parameter is increased until the noise becomes visibly noticeable. This experiment aims to observe how the appearance of colored images changes when noise is introduced into these channels individually. The following questions are explored: which channel proves more resilient to noise, which one results in a better visual outcome, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_2d_gauss_noise(mean, std, height, width):\n",
    "    return np.random.normal(mean, std, size=(height, width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = io.imread(img1_path)\n",
    "height, width, _ = arr.shape\n",
    "\n",
    "green_output = np.zeros_like(arr)\n",
    "green_output[:] = arr\n",
    "blue_output = np.zeros_like(arr)\n",
    "blue_output[:] = arr\n",
    "\n",
    "noise = gen_2d_gauss_noise(0, 15, height, width)\n",
    "\n",
    "# Convert int to float\n",
    "green_output = green_output.astype(np.float64)\n",
    "blue_output = blue_output.astype(np.float64)\n",
    "green_output[:, :, 1] += noise # Add noise to Green channel\n",
    "blue_output[:, :, 2] += noise # Add noise to Blue channel\n",
    "# Convert float to int\n",
    "green_output = green_output.astype(np.uint8)\n",
    "blue_output = blue_output.astype(np.uint8)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=3, figsize=(9, 6))\n",
    "\n",
    "ax[0, 0].imshow(green_output, vmin=0, vmax=255)\n",
    "ax[0, 0].set_title(\"Noisex1 on Green\", fontsize=fontsize)\n",
    "ax[0, 0].axis('off')\n",
    "ax[1, 0].imshow(blue_output, vmin=0, vmax=255)\n",
    "ax[1, 0].set_title(\"Noisex1 on Blue\", fontsize=fontsize)\n",
    "ax[1, 0].axis('off')\n",
    "\n",
    "green_output = green_output.astype(np.float64)\n",
    "blue_output = blue_output.astype(np.float64)\n",
    "green_output[:, :, 1] += noise\n",
    "blue_output[:, :, 2] += noise\n",
    "green_output = green_output.astype(np.uint8)\n",
    "blue_output = blue_output.astype(np.uint8)\n",
    "ax[0, 1].imshow(green_output, vmin=0, vmax=255)\n",
    "ax[0, 1].set_title(\"Noisex2 on Green\", fontsize=fontsize)\n",
    "ax[0, 1].axis('off')\n",
    "ax[1, 1].imshow(blue_output, vmin=0, vmax=255)\n",
    "ax[1, 1].set_title(\"Noisex2 on Blue\", fontsize=fontsize)\n",
    "ax[1, 1].axis('off')\n",
    "\n",
    "green_output = green_output.astype(np.float64)\n",
    "blue_output = blue_output.astype(np.float64)\n",
    "green_output[:, :, 1] += noise\n",
    "blue_output[:, :, 2] += noise\n",
    "green_output = green_output.astype(np.uint8)\n",
    "blue_output = blue_output.astype(np.uint8)\n",
    "ax[0, 2].imshow(green_output, vmin=0, vmax=255)\n",
    "ax[0, 2].set_title(\"Noisex3 on Green\", fontsize=fontsize)\n",
    "ax[0, 2].axis('off')\n",
    "ax[1, 2].imshow(blue_output, vmin=0, vmax=255)\n",
    "ax[1, 2].set_title(\"Noisex3 on Blue\", fontsize=fontsize)\n",
    "ax[1, 2].axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "The outcome is striking: the blue channel exhibits greater resilience to Gaussian noise.\n",
    "Now, let's delve into the reasons behind this phenomenon.\n",
    "\n",
    "The robustness of the blue channel to Gaussian noise can be attributed to several\n",
    "factors:\n",
    "\n",
    "- **Human Visual Perception:** The human eye is more sensitive to changes in luminance\n",
    "  (brightness) than to changes in chrominance (color). Since the blue channel\n",
    "  predominantly carries chrominance information, adding Gaussian noise to it affects\n",
    "  color perception less compared to the green channel.\n",
    "\n",
    "- **Noise Level:** The green channel often contains more detail and variation than the blue\n",
    "  channel in typical images. Therefore, when noise is added, the green channel is more\n",
    "  likely to reveal noticeable artifacts and degrade image quality.\n",
    "\n",
    "- **Color Composition:** In many natural scenes, blue objects or regions are relatively less\n",
    "  prevalent than green ones. This means that alterations in the blue channel's color are\n",
    "  often less noticeable to viewers than similar changes in the green channel.\n",
    "\n",
    "- **Color Balance:** Human vision is more forgiving of slight color imbalances in the blue\n",
    "  channel compared to the green channel. This is because our brains are accustomed to\n",
    "  tolerating minor variations in non-dominant colors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_Introduction_to_Computer_Vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
